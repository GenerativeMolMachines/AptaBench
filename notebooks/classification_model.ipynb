{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc079159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import rdFingerprintGenerator as rfg\n",
    "from rdkit.Chem import MACCSkeys, Descriptors\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433feb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('eremeeva_aptamers_dataset.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097d9e7c",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "210524be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_negatives_per_sequence(df: pd.DataFrame, n_neg_per_seq: int = 1, seed: int = 42):\n",
    "    \"\"\"\n",
    "    Для каждого уникального sequence добавляет до n_neg_per_seq новых негативных пар:\n",
    "      (sequence, canonical_smiles) с label=0, которых не было в исходном df.\n",
    "    Правила:\n",
    "      - пары не пересекаются с существующими (любой метки);\n",
    "      - pKd_value = NaN, origin='augmented_neg', source='augmentation';\n",
    "      - type берётся из исходных строк для этого sequence (если есть), иначе инференс по U/T;\n",
    "      - molecular_weight подтягивается по canonical_smiles, если известен.\n",
    "    \n",
    "    Возврат:\n",
    "      df_aug (исходные + новые негативы), df_neg (только сгенерированные).\n",
    "    \"\"\"\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    base = df.dropna(subset=[\"sequence\", \"canonical_smiles\"]).copy()\n",
    "\n",
    "    forbidden = set(map(tuple, base[[\"sequence\", \"canonical_smiles\"]].astype(str).values))\n",
    "\n",
    "    unique_sequences = base[\"sequence\"].astype(str).unique().tolist()\n",
    "    all_smiles = base[\"canonical_smiles\"].astype(str).unique().tolist()\n",
    "    mw_map = base.dropna(subset=[\"canonical_smiles\"]).groupby(\"canonical_smiles\")[\"molecular_weight\"].first().to_dict()\n",
    "\n",
    "    neg_rows = []\n",
    "\n",
    "    for s in unique_sequences:\n",
    "        type_series = base.loc[base[\"sequence\"].astype(str) == s, \"type\"].dropna()\n",
    "        if len(type_series) > 0:\n",
    "            type_val = str(type_series.iloc[0])\n",
    "        else:\n",
    "            type_val = \"RNA\" if \"U\" in s.upper() else \"DNA\"\n",
    "\n",
    "        used_smiles = set(base.loc[base[\"sequence\"].astype(str) == s, \"canonical_smiles\"].astype(str).tolist())\n",
    "\n",
    "        pool = [m for m in all_smiles if m not in used_smiles]\n",
    "\n",
    "        if not pool:\n",
    "            continue  \n",
    "\n",
    "        k = min(n_neg_per_seq, len(pool))\n",
    "        candidates = rng.sample(pool, k=k)\n",
    "\n",
    "        for m in candidates:\n",
    "            pair = (s, m)\n",
    "            if pair in forbidden:\n",
    "                continue  \n",
    "\n",
    "            neg_rows.append({\n",
    "                \"type\": type_val,\n",
    "                \"sequence\": s,\n",
    "                \"canonical_smiles\": m,\n",
    "                \"pKd_value\": np.nan,\n",
    "                \"label\": 0,\n",
    "                \"buffer\": np.nan,\n",
    "                \"origin\": \"augmented_neg\",\n",
    "                \"source\": \"augmentation\",\n",
    "                \"molecular_weight\": mw_map.get(m, np.nan),\n",
    "            })\n",
    "            forbidden.add(pair)\n",
    "\n",
    "    df_neg = pd.DataFrame(neg_rows)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col not in df_neg.columns:\n",
    "            df_neg[col] = np.nan\n",
    "    df_neg = df_neg[df.columns.tolist()]\n",
    "\n",
    "    df_aug = pd.concat([df, df_neg], ignore_index=True)\n",
    "\n",
    "    return df_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04615ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug = augment_negatives_per_sequence(df, n_neg_per_seq=3, seed=42)\n",
    "#df_aug.to_csv('eremeeva_aptamers_dataset_with_negatives.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed6ff0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nc1c(S(=O)(=O)O)cc(Nc2ccc(Nc3nc(Cl)nc(Nc4ccccc4S(=O)(=O)O)n3)c(S(=O)(=O)O)c2)c2c1C(=O)c1ccccc1C2=O',\n",
       " 'Nc1c(S(=O)(=O)O)cc(Nc2ccc(S(=O)(=O)O)c(Nc3nc(Cl)nc(Cl)n3)c2)c2c1C(=O)c1ccccc1C2=O',\n",
       " 'Nc1ncnc2c1ncn2C1OC(COP(=O)(O)OP(=O)(O)OP(=O)(O)O)C(O)C1O',\n",
       " 'Nc1ncnc2c1ncn2C1OC(COP(=O)(O)O)C(O)C1O',\n",
       " 'Cc1cc2nc3c(=O)[nH]c(=O)nc-3n(CC(O)C(O)C(O)COP(=O)(O)OP(=O)(O)OCC3OC(n4cnc5c(N)ncnc54)C(O)C3O)c2cc1C',\n",
       " 'Cc1cc2nc3c(=O)[nH]c(=O)nc-3n(CC(O)C(O)C(O)COP(=O)(O)O)c2cc1C',\n",
       " 'Nc1ncnc2c1ncn2C1OC(CO)C(O)C1O',\n",
       " 'Cc1cc2nc3c(=O)[nH]c(=O)nc-3n(CC(O)C(O)C(O)CO)c2cc1C',\n",
       " 'NC(=O)c1ccc[n+](C2OC(COP(=O)([O-])O)C(O)C2O)c1',\n",
       " 'CC1=C2N=C(C=C3N=C(C(C)=C4[N-]C(C(CC(N)=O)C4(C)CCC(=O)NCC(C)OP(=O)([O-])OC4C(CO)OC(n5cnc6cc(C)c(C)cc65)C4O)C4(C)N=C1C(CCC(N)=O)C4(C)CC(N)=O)C(CCC(N)=O)C3(C)C)C(CCC(N)=O)C2(C)CC(N)=O.[C-]#N.[Co+3]',\n",
       " 'C/C1=C2/[N-]C([C@H](CC(N)=O)[C@@]2(C)CCC(=O)NCC(C)O)[C@]2(C)N=C(/C(C)=C3\\\\N=C(/C=C4\\\\N=C1[C@@H](CCC(N)=O)C4(C)C)[C@@H](CCC(N)=O)[C@]3(C)CC(N)=O)[C@@H](CCC(N)=O)[C@]2(C)CC(N)=O.[C-]#N.[C-]#N.[Co]',\n",
       " 'Cn1c(=O)c2[nH]cnc2n(C)c1=O',\n",
       " 'Cn1c(=O)c2c(ncn2C)n(C)c1=O',\n",
       " 'Cn1c(=O)c2[nH]c(=O)[nH]c2n(C)c1=O',\n",
       " 'Cn1cnc2c1c(=O)[nH]c(=O)n2C',\n",
       " 'Cn1c(=O)[nH]c(=O)c2[nH]cnc21',\n",
       " 'Cn1cnc2[nH]c(=O)[nH]c(=O)c21',\n",
       " 'Cn1c(=O)n(CCC(=O)O)c(=O)c2[nH]cnc21',\n",
       " 'O=c1nc[nH]c2nc[nH]c12',\n",
       " 'Cn1c(=O)[nH]c2nc[nH]c2c1=O',\n",
       " 'N[C@@H]1C[C@@H](N)[C@@H](OCCCc2cn(Cc3cccc(Cn4cc(CCCO[C@@H]5[C@H](O)[C@H](O)[C@@H](N)C[C@H]5N)nn4)c3)nn2)[C@H](O)[C@H]1O',\n",
       " 'O=C(O)CCCCC1SCC2NC(=O)NC21',\n",
       " 'NCC1OC(OC2C(N)CC(N)C(OC3OC(CO)C(O)C(N)C3O)C2O)C(N)CC1O',\n",
       " 'CN(C)c1ccc(C(=C2C=CC(=[N+](C)C)C=C2)c2ccccc2)cc1.[Cl-]',\n",
       " 'CN(C)C1C(=O)C(C(N)=O)=C(O)C2(O)C(=O)C3=C(O)c4c(O)cccc4C(C)(O)C3CC12',\n",
       " 'Cc1c2ccncc2c(C)c2c1[nH]c1ccccc12',\n",
       " 'O=C(Cc1ccccc1)OC[C@H]1OC(=O)N[C@@H]1CN1CCN(c2ccccc2)CC1',\n",
       " 'CC(=O)c1ccc(NC(=O)OC[C@H]2OC(=O)N[C@@H]2CN2CCN(c3ccccc3)CC2)cc1',\n",
       " 'CNC1C(OC2C(OC(=O)c3c(O)ccc4c(C)cc(OC)cc34)C=C3C#CC4(C5COC(=O)O5)OC4C#CCC32)OC(C)C(O)C1O',\n",
       " 'N[C@@H]1[C@@H](O[C@@H]2O[C@H]3C(=O)c4cc5ccccc5cc4[C@@H]3[C@@]23C(=O)C=Cc2ccccc23)O[C@H](CO)[C@H](O)[C@H]1O',\n",
       " 'N[C@H]1[C@H](O[C@@H]2C=Cc3ccccc3[C@@]23C(=O)O[C@@H]2C(=O)c4cc5ccccc5cc4[C@@H]23)O[C@@H](CO)[C@@H](O)[C@@H]1O',\n",
       " 'CN[C@@H]1[C@@H](O[C@@H]2c3cc4ccccc4cc3[C@H]3[C@H]2C=C[C@@]32C(=O)C=Cc3ccc(OC)cc32)O[C@@H](C)[C@@H](O)[C@H]1O',\n",
       " 'COc1ccc2c(c1)[C@]1(C=C[C@H]3[C@H](O[C@H]4O[C@H](CO)[C@H](O)[C@@H](O)[C@@H]4N)c4cc5ccccc5cc4[C@@H]31)C(=O)C=C2',\n",
       " 'CN[C@@H]1[C@@H](O[C@H]2c3cc4ccccc4cc3[C@@H]3[C@@H]2C=C[C@@]32C(=O)C=Cc3ccc(OC)cc32)O[C@@H](C)[C@@H](O)[C@H]1O',\n",
       " 'CNC1C(OC2C(OC3C(O)C(O)C(N=C(N)N)C(O)C3N=C(N)N)OC(C)C2(O)C=O)OC(CO)C(O)C1O',\n",
       " 'NCC1OC(OC2C(CO)OC(OC3C(O)C(N)CC(N)C3OC3OC(CO)C(O)C(O)C3N)C2O)C(N)C(O)C1O',\n",
       " 'NC[C@@H]1O[C@H](O[C@H]2[C@@H](O)[C@H](O[C@H]3O[C@@H](CNc4c5ccccc5nc5ccccc45)[C@H](O)[C@@H](N)[C@@H]3O)[C@@H](N)C[C@H]2N)[C@H](N)C[C@@H]1O',\n",
       " 'NCC1OC(OC2C(N)CC(N)C(OC3OC(CO)C(O)C(N)C3O)C2O)C(O)C(O)C1O',\n",
       " 'NCC1OC(OC2C(N)CC(N)C(OC3OC(CO)C(O)C(N)C3O)C2O)C(N)C(O)C1O',\n",
       " 'NCC1OC(OC2C(CO)OC(OC3C(O)C(N)CC(N)C3OC3OC(CN)C(O)C(O)C3N)C2O)C(N)C(O)C1O',\n",
       " 'CNC1C(O)C(OC2C(N)CC(N)C(OC3OC(CN)CCC3N)C2O)OCC1(C)O',\n",
       " 'NCCC(O)C(=O)NC1CC(N)C(OC2OC(CN)C(O)C(O)C2O)C(O)C1OC1OC(CO)C(O)C(N)C1O',\n",
       " 'CNC1C(O)C(NC)C2OC3(O)C(=O)CC(C)OC3OC2C1O',\n",
       " 'CNC1CC(N)C(O)C(OC2OC(CO)C(O)C3OC4(OC(C(N)CO)C(O)C(O)C4O)OC23)C1O',\n",
       " 'CNC1C(O)C(OC2C(N)CC(N)C(OC3OC(CN)=CCC3N)C2O)OCC1(C)O',\n",
       " 'NCCC(O)C(=O)NC1CC(N)C(OC2OC(CN)C(O)C(O)C2N)C(OC2OC(CO)C(O)C2O)C1O',\n",
       " 'CNC1C(OC2OC(CO)C(N)C(O)C2O)OC2CC(N)C(OC3C(N)CC(N)C(O)C3O)OC2C1O',\n",
       " 'NCC1OC(OC2C(N)CC(N)C(O)C2O)C(N)C(O)C1O',\n",
       " 'CNC1C(O)C(OC2C(N)CC(N)C(OC3OC(C(C)O)C(O)C(O)C3N)C2O)OCC1(C)O',\n",
       " 'NCC1OC(OC2C(N)CC(N)C(O)C2OC2OC(CO)C(O)C2O)C(N)C(O)C1O',\n",
       " 'CC(C)[C@H](NC(=O)[C@@H](CO)NC(=O)CCCN)C(=O)NCc1ccc(Nc2c3ccccc3nc3c(C(=O)N[C@H](CCCNC(=N)N)C(N)=O)cccc23)cc1',\n",
       " 'COc1ccc(N2C(=O)O[C@H](COC(=O)Cc3ccccc3)[C@H]2Cc2ccccc2)cc1',\n",
       " 'O=C(Cc1ccccc1)OC[C@H]1OC(=O)N[C@@H]1Cc1ccccc1',\n",
       " 'COC(=O)C1C(O)CCC2CN3CCc4c([nH]c5ccccc45)C3CC21',\n",
       " 'N[C@@H]1C[C@H](N)[C@@H](OCSc2ccnc3cc(C(F)(F)F)ccc23)[C@H](O)[C@@H]1O',\n",
       " 'N[C@@H]1C[C@H](N)[C@H](OCCCCCCCCCCCCO[C@@H]2[C@H](O)[C@H](O)[C@@H](N)C[C@H]2N)[C@H](O)[C@H]1O',\n",
       " 'N[C@@H]1C[C@H](N)[C@@H](O)[C@H](O)[C@H]1OCc1ccc(CCc2ccc(CO[C@@H]3[C@@H](O)[C@H](O)[C@@H](N)C[C@@H]3N)cc2)cc1',\n",
       " 'N[C@@H]1C[C@H](N)[C@@H](O)[C@H](O)[C@H]1OCc1ccc(CCc2ccc(CO)cc2)cc1',\n",
       " 'Nc1ncnc2nc[nH]c12',\n",
       " 'Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H](O)[C@H]1O',\n",
       " 'CO[C@H]1[C@@H](O)[C@H](n2cnc3c(N)ncnc32)O[C@@H]1CO',\n",
       " 'Nc1nc2c(ncn2[C@@H]2O[C@H](CO)[C@@H](O)[C@H]2O)c(=O)[nH]1',\n",
       " 'Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)C[C@H]1O',\n",
       " 'Nc1ncnc2c1ncn2[C@H]1C[C@H](O)[C@@H](CO)O1',\n",
       " 'O=c1ccn([C@@H]2O[C@H](CO)[C@@H](O)[C@H]2O)c(=O)[nH]1',\n",
       " 'Nc1ncnc2c1ncn2[C@@H]1O[C@H](COP(=O)(O)OP(=O)(O)OP(=O)(O)O)[C@@H](O)[C@H]1O',\n",
       " 'Nc1ccn([C@@H]2O[C@H](CO)[C@@H](O)[C@H]2O)c(=O)n1',\n",
       " 'CO[C@@H]1[C@H](O)[C@@H](CO)O[C@H]1n1cnc2c(N)ncnc21',\n",
       " 'Nc1ncnc2c1ncn2[C@H]1O[C@@H](CO)[C@H](O)[C@@H]1O',\n",
       " 'N=C1N[C@@H]2[C@H](CS[C@H]2CCCCC(=O)NCCOCCOCCNC(=O)CCCC[C@H]2SC[C@H]3NC(=N)N[C@@H]32)N1',\n",
       " 'N=C1N[C@@H]2[C@H](CS[C@H]2CCCCC(=O)NCCOCCOCCN)N1',\n",
       " 'COc1ccc2nc3cc(Cl)ccc3c(NCCCCc3c(N)nc(N)nc3N)c2c1',\n",
       " 'O=C(Cc1ccccc1)OC[C@@H]1OC(=O)N[C@@H]1CN1CCN(c2ccccc2)CC1',\n",
       " 'CC(=O)c1ccc(NC(=O)OC[C@@H]2OC(=O)N[C@@H]2CN2CCN(c3ccccc3)CC2)cc1',\n",
       " 'COc1ccc(NCc2ccc([N+](=O)[O-])s2)cc1OC',\n",
       " 'O=C1NC(=S)N/C1=C/c1ccc2ccccc2c1',\n",
       " 'O=C(N/N=C\\\\c1ccc(Br)cc1)c1cc[n+](Cc2ccccc2)cc1',\n",
       " 'CC1CCN(c2ccc(N)cc2)CC1',\n",
       " 'O=[N+]([O-])c1ccc(SCCO)c2ncccc12',\n",
       " 'O=C1Oc2ccccc2C(=O)/C1=C\\\\N1C(=O)N/C(=C\\\\c2ccccc2O)C1=O',\n",
       " 'Nc1c(S(=O)(=O)O)cc(Nc2ccc(S(N)(=O)=O)cc2)c2c1C(=O)c1ccccc1C2=O',\n",
       " 'O=C1c2ccccc2C(=O)[C@@H]2C(NCCO)=CC=C(NCCO)[C@@H]12',\n",
       " 'CNC(=O)c1cc2c(=O)n3cccc(C)c3nc2n(CCCO)c1=N',\n",
       " 'CN1CCN(CCCN2c3ccccc3Sc3ccc(C(F)(F)F)cc32)CC1',\n",
       " 'NCCCC[C@H](NC(=O)[C@H](CSSC[C@H](NC(=O)[C@@H]1CCCN1C(=O)c1ccc2c(c1)OCO2)C(=O)N[C@H](CCCCN)C(=O)NCCCN)NC(=O)[C@@H]1CCCN1C(=O)c1ccc2c(c1)OCO2)C(=O)NCCCN',\n",
       " 'CCc1nc2ccccc2cc1C(=O)N1CCC[C@H]1C(=O)N[C@@H](CSSC[C@H](NC(=O)[C@@H]1CCCN1C(=O)c1cc2ccccc2nc1CC)C(=O)N[C@H](CCCCN)C(=O)NCCCN)C(=O)N[C@H](CCCCN)C(=O)NCCCN',\n",
       " 'CCc1nc2ccccc2cc1C(=O)N[C@@H](CC(N)=O)C(=O)N[C@H](CSSC[C@H](NC(=O)[C@@H]1CCCN1C(=O)c1cc2ccccc2nc1CC)C(=O)N[C@H](CCCCN)C(=O)NCCCN)C(=O)N[C@@H](CCCCN)C(=O)NCCCN',\n",
       " 'CCc1nc2ccccc2cc1C(=O)N1CCC[C@H]1C(=O)N[C@@H](CSSC[C@@H](NC(=O)[C@@H]1CCCN1C(=O)c1ccc2c(c1)OCO2)C(=O)N[C@@H](CCCCN)C(=O)NCCCN)C(=O)N[C@H](CCCCN)C(=O)NCCCN',\n",
       " '[NH3+]CCCC[C@H]([NH3+])C(=O)Nc1ccc2c(c1)C1c3cc(NC(=O)[C@@H]([NH3+])CCCC[NH3+])ccc3C2c2ccc(NC(=O)[C@@H]([NH3+])CCCC[NH3+])cc21',\n",
       " 'NC(=[NH2+])NCCC[C@H]([NH3+])C(=O)Nc1ccc2c(c1)C1c3cc(NC(=O)[C@@H]([NH3+])CCCNC(N)=[NH2+])ccc3C2c2ccc(NC(=O)[C@@H]([NH3+])CCCNC(N)=[NH2+])cc21',\n",
       " 'CCc1nc2cc3ccccc3cc2cc1C(=O)N1CCC[C@H]1C(=O)N[C@@H](C/C=C\\\\C[C@H](NC(=O)[C@@H]1CCCN1C(=O)c1cc2cc3ccccc3cc2nc1CC)C(=O)N[C@@H](CCCC[NH3+])C(=O)NCCC[NH3+])C(=O)N[C@@H](CCCC[NH3+])C(=O)NCCC[NH3+]',\n",
       " 'C[n+]1c(/C=C/c2cc3ccccc3[nH]2)ccc2ccccc21',\n",
       " 'CCn1c2ccccc2c2cc(/C=C/c3ccc4ccccc4[n+]3C)ccc21',\n",
       " 'C[n+]1c(C=Cc2ccc(N3CCOCC3)cc2)cc(N2CC[NH+](C)CC2)c2ccccc21',\n",
       " 'C[n+]1c(C=Cc2cc3ccccc3[nH]2)cc(N2CC[NH+](C)CC2)c2ccccc21',\n",
       " 'CCn1c2ccccc2c2cc(C=Cc3cc(N4CC[NH+](C)CC4)c4ccccc4[n+]3C)ccc21',\n",
       " 'Nc1ccc(-c2cc3ccc(C4=[NH+]CCN4)cc3[nH]2)cc1',\n",
       " 'NC(=[NH2+])c1ccc(Nc2ccc(-c3cc4ccc(C(N)=[NH2+])cc4[nH]3)cc2)cc1',\n",
       " 'Nc1cccc(-c2nc3ccc(-c4ccc5nc(-c6cccc(N)c6)[nH]c5c4)cc3[nH]2)c1',\n",
       " 'N#Cc1c(N2CCCC2)nc(N)c2c(N)nc(N3CCCC3)cc12',\n",
       " 'O=C(Nc1ccc(NC(=O)c2ccc(F)cc2)nc1)c1ccncc1',\n",
       " 'CCN(CC)CCOc1ccc(Nc2nc(-c3ccccc3NC(=O)CCN3CCN(C)CC3)nc3ccccc23)cc1',\n",
       " 'C[NH+]1CCN(c2ccc(-c3ccc4[nH]c(-c5cc(C(C)(C)C)c(OCCCC(=O)NCCCN=[N+]=[N-])c(C(C)(C)C)c5)nc4c3)cc2)CC1',\n",
       " 'NC(=[NH2+])c1ccc(-c2ccc(-c3ccc(-c4ccc(C(N)=[NH2+])cn4)o3)o2)nc1',\n",
       " 'NC(=[NH2+])c1ccc(-c2ccc(-c3ccc(-c4ccc(C(N)=[NH2+])cn4)s3)s2)nc1',\n",
       " 'O=c1c(O)c(-c2cc(O)c(O)c(O)c2)oc2cc(O)cc(O)c12',\n",
       " '[NH3+]CCNc1c2c(c(NCC[NH3+])c3occc13)C(=O)c1ccccc1C2=O',\n",
       " '[NH3+]CCNc1c2c(c(NCC[NH3+])c3sccc13)C(=O)c1ccccc1C2=O',\n",
       " 'CC[NH+]1CCN(c2ccc3cc(-c4cn5cc(C)nc(C)c5n4)c(=O)oc3c2)C[C@@H]1C',\n",
       " 'c1ccc2c(NCc3cn(CCC[NH+]4CCCCC4)nn3)c3oc4ccccc4c3[nH+]c2c1',\n",
       " 'O=c1c2c(-c3ccoc3)csc2nc2n1Cc1nc3scc(-c4ccco4)c3c(=O)n1C2',\n",
       " 'NC(N)=N/N=C/c1ccc(-c2cc3ccc(/C=N/N=C(N)N)cc3s2)cc1',\n",
       " 'CCc1nc2cc3ccccc3cc2cc1C(=O)N(C)[C@@H](C/C=C/C[C@@H](C(=O)N1CCC[C@H]1C(=O)N(C)[C@@H](Cc1ccccc1)C(=O)NCCC[NH3+])N(C)C(=O)c1cc2cc3ccccc3cc2nc1CC)C(=O)N1CCC[C@H]1C(=O)N(C)[C@@H](Cc1ccccc1)C(=O)NCCC[NH3+]',\n",
       " 'CC(=O)c1ccc(-c2cnc(NCc3cccc(C(C)=O)c3)n2C)cc1',\n",
       " 'Cn1cc(C(=O)N2CCC(c3ccc(CN4CC(O)C4)cc3)CC2)c2ccccc21',\n",
       " 'Cc1nc2sccn2c1C(=O)N1CCC(c2ccc(CN3CC(O)C3)cc2)CC1',\n",
       " 'Cc1c2cc[n+](CCN3CCCCC3)cc2c(C)c2c1[nH]c1ccc(O)cc12',\n",
       " 'Cc1cn2cc(-c3cc(=O)n4cc(N5CCN(C)CC5)ccc4n3)cc(F)c2n1',\n",
       " 'Cc1cn2cc(-c3cc4ccc(N5CCN[C@@H](C)C5)cc4oc3=O)nc2c(C)n1',\n",
       " 'Cc1cn2cc(-c3cc4ccc(N5CCN(CCNC(=O)OC(C)(C)C)[C@@H](C)C5)cc4oc3=O)nc2c(C)n1',\n",
       " 'CN1CCN(c2ccc3cc(-c4ccccc4Cl)c(=O)oc3c2)CC1',\n",
       " 'CN1CCN(c2ccc3cc(-c4cccc(Cl)c4)c(=O)oc3c2)CC1',\n",
       " 'CN1CCN(c2ccc3cc(-c4ccc(Cl)cc4)c(=O)oc3c2)CC1',\n",
       " 'CN1CCN(c2cc(F)c3cc(-c4cccc(Cl)c4)c(=O)oc3c2)CC1',\n",
       " 'CN1CCN(c2cc(F)c3cc(-c4ccc(Cl)cc4)c(=O)oc3c2)CC1',\n",
       " 'Cc1c(-c2cccc(Cl)c2)c(=O)oc2cc(N3CCN(C)CC3)ccc12',\n",
       " 'Cc1c(-c2ccc(Cl)cc2)c(=O)oc2cc(N3CCN(C)CC3)ccc12',\n",
       " 'O=c1oc2cc(N3CCNCC3)ccc2cc1-c1cn2ccccc2n1',\n",
       " 'COc1cn2cc(-c3cc4ccc(N5CCNCC5)cc4oc3=O)nc2cn1',\n",
       " 'CN(C)c1ccc2c(-c3ccc(C(=O)NCC4OC(OC5C(N)CC(N)C(OC6OC(CO)C(O)C(N)C6O)C5O)C(N)CC4O)cc3C(=O)O)c3ccc(=[N+](C)C)cc-3oc2c1',\n",
       " 'C(=NNC1=NCCN1)c1c2ccccc2c(C=NNC2=NCCN2)c2ccccc12',\n",
       " 'C[NH+](C)CCC[NH+]=C(N)c1ccc(C(N)=[NH+]CCC[NH+](C)C)cc1',\n",
       " 'CN(C)CCCN=C(N)c1ccc(-c2ccc(-c3nc4ccc(C(N)=NCCCN(C)C)cc4[nH]3)o2)cc1',\n",
       " 'CC(C)c1ccc2nc3ccc(C(=O)NCCN(C)C)cn3c(=O)c2c1',\n",
       " 'COc1cc(-c2nc3cc4[nH]c(=O)[nH]c4cc3[nH]2)cc(OC)c1O',\n",
       " 'c1cc(-c2ccc(-c3ccc(C4=[NH+]CCN4)cc3)o2)ccc1C1=[NH+]CCN1',\n",
       " 'NC(=[NH2+])c1ccc(-c2ccc(-c3ccc(C(N)=[NH2+])cc3)o2)cc1',\n",
       " 'O=C(/C=C/c1ccccc1)N1CCN(C(=O)/C=C/c2ccccc2)c2ccccc21',\n",
       " 'CCN(CC)CC(=O)Nc1cccc2c1C(=O)c1c(c(O)c3ccccc3c1O)C2=O',\n",
       " 'O=C(O)C1CCc2nc(NCc3ccccc3)nc(NCc3ccccc3)c2C1',\n",
       " 'O=C1c2ccccc2C(=O)c2c(NCCN3CCOCC3)ccc(NCCN3CCOCC3)c21',\n",
       " 'c1ccc(-c2nnc(-c3nc(NCCCN4CCC(N5CCCCC5)CC4)c4ccccc4n3)o2)cc1',\n",
       " 'Fc1ccc(-c2nnc(-c3nc(NCCc4ccco4)c4ccccc4n3)o2)cc1',\n",
       " 'Fc1ccc(-c2nnc(-c3nc(NC4CCCCC4)c4ccccc4n3)o2)cc1',\n",
       " 'CCCSCCCNc1nc(-c2nnc(-c3ccccc3)o2)nc2ccccc12',\n",
       " 'c1ccc(-c2nnc(-c3nc(NCCc4cccs4)c4ccccc4n3)o2)cc1',\n",
       " 'CN(C)c1ccc(-c2nc(-c3nnc(-c4ccc(Cl)cc4)o3)nc3ccccc23)cc1',\n",
       " 'Cc1cccc(-c2nnc(-c3nc(NCCc4cnc[nH]4)c4ccccc4n3)o2)c1',\n",
       " 'Cc1cccc(-c2nnc(-c3nc(NCCN4CCOCC4)c4ccccc4n3)o2)c1',\n",
       " 'Cc1cccc(-c2nnc(-c3nc(NCCc4c(C)noc4C)c4ccccc4n3)o2)c1',\n",
       " 'Cc1ccc(-c2nnc(-c3nc(N4CCCCC4)c4ccccc4n3)o2)cc1',\n",
       " 'Cc1ccc(-c2nnc(-c3nc(NCc4cccc5c4OCO5)c4ccccc4n3)o2)cc1',\n",
       " 'Cc1ccc(-c2nnc(-c3nc(NCCc4ccc(S(N)(=O)=O)cc4)c4ccccc4n3)o2)cc1',\n",
       " 'Cc1ccc(-c2nnc(-c3nc(NCCN4CCCC4)c4ccccc4n3)o2)cc1',\n",
       " 'Cc1ccc(-c2nnc(-c3nc(NCCCN4CCc5ccccc5C4)c4ccccc4n3)o2)cc1',\n",
       " 'c1ccc(-c2nnc(-c3nc(NCCCCN4CCC(N5CCCCC5)CC4)c4ccccc4n3)o2)cc1',\n",
       " 'NCc1cc(NC(=O)c2ccccn2)cc(-c2nc(C3CCOC3)no2)c1',\n",
       " 'Cc1ccc(NCCCNC(=O)c2cn(CCN)nn2)nc1',\n",
       " 'Fc1ccc(Oc2ncccc2CNC2CN3CCC2CC3)cc1F',\n",
       " 'Cn1nc(CN2CCCCC(N)C2)c2c(Cl)cccc21',\n",
       " 'NCCc1cc(N2CCC(N3CCC(O)CC3)CC2)ncn1',\n",
       " 'Cc1cc(N2CCN(C(=O)CCc3cc4n(n3)CCNC4)CC2)nc(N)n1',\n",
       " 'CC(CCc1ccco1)NC1CCC2(CCNCC2)CC1',\n",
       " 'COc1ccc(CN2CCC(N3CCN(CCO)CC3)CC2)cc1OCc1ccccc1',\n",
       " 'Nc1nnc(CCCNc2nccc(-c3ccncc3)n2)s1',\n",
       " 'CC(C)OC(=O)c1ccc(Nc2nc3ccccc3c3nncn23)cc1',\n",
       " 'Nc1nc(CN2CCCCCC2)nc(Nc2ccc(F)cc2)n1',\n",
       " 'COc1cc(C=CC(=O)CC(=O)C=Cc2ccc(O)c(OC)c2)ccc1O',\n",
       " 'N[C@@H]1C[C@@H](N)[C@@H](OCCCc2cn(Cc3ccc(Cn4cc(CCCO[C@@H]5[C@H](O)[C@H](O)[C@@H](N)C[C@H]5N)nn4)cc3)nn2)[C@H](O)[C@H]1O',\n",
       " 'Cc1cc(C)c(Cn2cc(CCCO[C@H]3[C@H](O)[C@@H](O)[C@H](N)C[C@H]3N)nn2)c(C)c1Cn1cc(CCCO[C@@H]2[C@H](O)[C@H](O)[C@@H](N)C[C@H]2N)nn1',\n",
       " 'N[C@@H]1C[C@@H](N)[C@@H](OCCCc2cn(Cc3cccc(Cn4cc(CCCO[C@@H]5[C@H](O)[C@H](O)[C@@H](N)C[C@H]5N)nn4)n3)nn2)[C@H](O)[C@H]1O',\n",
       " 'CN(C)c1ccc2c(-c3ccccc3)c3ccc(=[N+](C)C)cc-3oc2c1',\n",
       " 'CN(C)c1ccc2cc3ccc(=[N+](C)C)cc-3oc2c1.[Cl-]',\n",
       " 'NCC1OC(OC2C(N)CC(N)C(OC3OC(CN)C(N)C(O)C3O)C2O)C(N)CC1O',\n",
       " 'NCC1OC(OC2C(N)CC(N)C(OC3OC(CN)C(OC4OC(CO)C(N)C(O)C4O)C(N)C3O)C2O)C(N)CC1O',\n",
       " 'NCC1OC(OC2C(N)CC(N)C(OC3OC(CN)C(OC4OC(CO)C(O)C(N)C4O)C(O)C3N)C2O)C(N)CC1O',\n",
       " 'NCC1OC(OC2C(N)CC(N)C(OC3OC(CN)C(O)C(N)C3O)C2O)C(N)CC1O',\n",
       " 'NCC1OC(OC2C(N)CC(N)C(OC3OC(COC4OC(CO)C(O)C(O)C4N)C(O)C(O)C3N)C2O)C(N)CC1O',\n",
       " 'NCC1OC(OC2C(N)CC(N)C(OC3OC(CN)C(O)C(OC4OC(CO)C(N)C(O)C4O)C3O)C2O)C(N)CC1O',\n",
       " 'NCC1OC(OC2C(N)CC(N)C(OC3OC(CN)C(OC4OC(CO)C(O)C(O)C4N)C(N)C3O)C2O)C(N)CC1O',\n",
       " 'NCC1OC(OC2C(N)CC(N)C(OC3OC(COC4OC(CN)C(O)C(O)C4O)C(N)C(O)C3N)C2O)C(N)CC1O',\n",
       " 'NCC1OC(OC2C(N)CC(N)C(OC3OC(CN)C(O)C(OC4OC(CO)C(O)C(O)C4N)C3N)C2O)C(N)CC1O',\n",
       " 'CCOC(=O)c1c2c(n3ccccc13)C(=O)c1ccccc1C2=O',\n",
       " 'C[N+](C)(C)CCN[N+]1(C)CCCc2ccccc21',\n",
       " 'Cc1cc(N2CCN(C)CC2)n2nc(-c3ccc(Cl)cc3)nc2n1',\n",
       " 'COC1=C(C)C(=O)c2c(c(COC(N)=O)c3n2C[C@H]2[C@@H]3N2C)C1=O',\n",
       " 'CC(N)=[NH+]CCCC[C@H]([NH3+])C(=O)[O-]',\n",
       " 'CC(C)CC(NC(=O)C(CCC(N)=O)NC(=O)C1CCCN1C(=O)C(N)CCCCN)C(=O)NC(Cc1c[nH]c2ccccc12)C(=O)N1CCCC1C(=O)O',\n",
       " 'CNC1C(O)C(OC2C(N)CC(N)C(OC3OC(C(C)CCNC(=O)c4ccc(-c5c6ccc(=[N+](C)C)cc-6oc6cc(N(C)C)ccc56)c(C(=O)O)c4)CCC3N)C2O)OCC1(C)O',\n",
       " 'CN(C)c1ccc2c(-c3ccc(C(=O)NCC4OC(OC5C(N)CC(N)C(OC6OC(CO)C(O)C(N)C6O)C5O)C(N)C(O)C4O)cc3C(=O)O)c3ccc(=[N+](C)C)cc-3oc2c1',\n",
       " 'O=C(Cc1ccccc1)OC[C@H]1OC(=O)NC1CN1CCN(c2ccccc2)CC1',\n",
       " 'O=C(Cc1ccccc1)OCC1OC(=O)N[C@H]1CN1CCN(c2ccccc2)CC1',\n",
       " 'CC(=O)c1ccc(NC(=O)OC[C@H]2OC(=O)NC2CN2CCN(c3ccccc3)CC2)cc1',\n",
       " 'CC(=O)c1ccc(NC(=O)OCC2OC(=O)N[C@H]2CN2CCN(c3ccccc3)CC2)cc1',\n",
       " 'CC(=O)c1ccc(NC(=O)OC[C@H]2OC(=O)N[C@H]2CN2CCN(c3ccccc3)CC2)cc1',\n",
       " 'Nc1ncnc2c1ncn2C1OC2COP(=O)(O)OC2C1O',\n",
       " 'NCCc1ccc(O)c(O)c1',\n",
       " 'CC1=C2N=C(C=C3NC(=C(C)C4=NC(C)(C5N=C1C(C)(CCC(=O)NCC(C)OP(=O)(O)OC1C(CO)OC([n+]6c[nH]c7cc(C)c(C)cc76)C1O)C5CC(N)=O)C(C)(CC(N)=O)C4CCC(=N)[O-])C(C)(CC(N)=O)C3CCC(=N)[O-])C(C)(C)C2CCC(=N)[O-].[C]#N.[Co+2]',\n",
       " 'NC(=O)C(N)Cc1ccc(O)cc1',\n",
       " 'COc1ccc2c3c1OC1C(O)C=CC4C(C2)N(C)CCC341',\n",
       " 'CCN(CC)c1ccc2c(-c3ccc(S(=O)(=O)O)cc3S(=O)(=O)[O-])c3ccc(=[N+](CC)CC)cc-3oc2c1',\n",
       " 'NC(Cc1cc(I)c(Oc2cc(I)c(O)c(I)c2)c(I)c1)C(=O)O',\n",
       " 'OCC1OC(n2cnc3c2NC=NCC3O)CC1O',\n",
       " 'CCCCCCCCCCCCCC=CC(O)C(N)COP(=O)([O-])OCC[N+](C)(C)C',\n",
       " 'Cc1c(-c2ccc(O)cc2)nn(-c2ccc(O)cc2)c1-c1ccc(CCCN2CCCCC2)cc1',\n",
       " 'NC(=O)CCC1NC(=O)C(Cc2ccccc2)NC(=O)C(Cc2ccc(O)cc2)NC(=O)C(N)CSSCC(C(=O)N2CCCC2C(=O)NC(CCCN=C(N)N)C(=O)NCC(N)=O)NC(=O)C(CC(N)=O)NC1=O',\n",
       " 'CN(C)C1C(=O)C(C(N)=O)=C(O)C2(O)C(=O)C3=C(O)c4c(O)cccc4C(C)(O)C3C(O)C12',\n",
       " '[As]',\n",
       " 'COc1cccc2c1C(=O)c1c(O)c3c(c(O)c1C2=O)CC(O)(C(C)=O)CC3OC1CC(N)C(O)C(C)O1',\n",
       " 'NC(CCC(=O)O)C(=O)O',\n",
       " 'CC(CCC(=O)O)C1CCC2C3C(O)CC4CC(O)CCC4(C)C3CC(O)C12C',\n",
       " 'CC1Cc2c(Cl)cc(C(=O)NC(Cc3ccccc3)C(=O)O)c(O)c2C(=O)O1',\n",
       " 'COC(=O)CCCC(C)O',\n",
       " 'CCC(C)C(N)C(=O)O',\n",
       " 'CCC(C)C(NC(=O)C(Cc1ccc(O)cc1)NC(=O)C(Cc1cnc[nH]1)NC(=O)C(CCCNC(=N)N)NC(=O)C(CC(C)C)NC(=O)C(C)NC(=O)C(CO)NC(=O)C(Cc1ccc(O)cc1)NC(=O)C(Cc1ccc(O)cc1)NC(=O)C(CCCNC(=N)N)NC(=O)C(C)NC(=O)C(CC(C)C)NC(=O)C(CC(=O)O)NC(=O)C(CCC(=O)O)NC(=O)C(C)NC(=O)C1CCCN1C(=O)C(C)NC(=O)C(CC(=O)O)NC(=O)C(CCC(=O)O)NC(=O)CNC(=O)C1CCCN1C(=O)C(CC(N)=O)NC(=O)C(CC(=O)O)NC(=O)C1CCCN1C(=O)C(CCCCN)NC(=O)C(CO)NC(=O)C1CCCN1C(=O)C(N)Cc1ccc(O)cc1)C(=O)NC(CC(N)=O)C(=O)NC(CC(C)C)C(=O)NC(C(=O)NC(C(=O)NC(CCCNC(=N)N)C(=O)NC(CCC(N)=O)C(=O)NC(CCCNC(=N)N)C(=O)NC(Cc1ccc(O)cc1)C(N)=O)C(C)O)C(C)CC',\n",
       " 'CC(=O)NC1C(O)CC(OC2C(O)C(CO)OC(OC3C(CO)OC(O)C(NC(C)=O)C3OC3OC(C)C(O)C(O)C3O)C2O)(C(=O)[O-])OC1C(O)C(O)CO.[Na+]',\n",
       " 'Cc1cc2c(cc1S(=O)(=O)N1CCN(C)CC1)S(=O)(=O)NC(C1CCCC1)N2',\n",
       " 'CCCCC(C)C(OC(=O)CC(CC(=O)O)C(=O)O)C(CC(C)CC(O)CCCCC(O)CC(O)C(C)N)OC(=O)CC(CC(=O)O)C(=O)O',\n",
       " 'NC(=O)CC(N)C(=O)NCC(=O)NC(CCCN=C(N)N)C(=O)O',\n",
       " 'NC(Cc1c[nH]c2ccccc12)C(=O)O',\n",
       " 'CC(C)(COP(=O)(O)OP(=O)(O)OCC1OC(n2cnc3c(N)ncnc32)C(O)C1OP(=O)(O)O)C(O)C(=O)NCCC(=O)NCCSCC(=O)c1ccc(O)cc1O',\n",
       " 'CC(NC(=O)CCC(=O)O)C(=O)NC(C)C(=O)N1CCCC1C(=O)NC(Cc1ccccc1)C(=O)Nc1ccc([N+](=O)[O-])cc1',\n",
       " 'NC(Cc1cnc[nH]1)C(=O)NC(Cc1cnc[nH]1)C(=O)NC(Cc1cnc[nH]1)C(=O)NC(Cc1cnc[nH]1)C(=O)NC(Cc1cnc[nH]1)C(=O)NC(Cc1cnc[nH]1)C(=O)O',\n",
       " 'Nc1nc2c([nH]c(=O)n2C2CC(O)C(CO)O2)c(=O)[nH]1',\n",
       " 'CC(=NC#N)N(C)Cc1ccc(Cl)nc1',\n",
       " 'CC(C)(c1ccc(O)cc1)c1ccc(O)cc1',\n",
       " 'O=C1CCC(N2C(=O)c3ccccc3C2=O)C(=O)N1',\n",
       " 'C=CCOCC1CO1',\n",
       " 'COc1cc(C=C2N=CNC2=O)cc(OC)c1O',\n",
       " 'O=C1NC=NC1=Cc1cc(F)c(O)c(F)c1',\n",
       " 'COc1ccc(CN2CCN(Cc3ccccc3)CC2)c(O)c1OC',\n",
       " 'CC(C)Cc1ccc(C(C)C(=O)O)cc1',\n",
       " '[Ce]',\n",
       " 'CC(=O)NC1C(O)CC(O)(C(=O)O)OC1C(O)C(O)CO',\n",
       " 'CC1OC(OC2C(O)CC(OC3C(O)CC(OC4CCC5(C)C(CCC6C5CC(O)C5(C)C(C7=CC(=O)OC7)CCC65O)C4)OC3C)OC2C)CC(O)C1O',\n",
       " 'OCC1OC(OC2C(CO)OC(O)C(O)C2O)C(O)C(O)C1O',\n",
       " 'CC1=C(CCC(=O)O)c2cc3nc(cc4[nH]c(cc5[nH]c(cc1n2)c(C)c5C(C)O)c(C)c4C(C)O)C(C)=C3CCC(=O)O',\n",
       " 'Cn1c[n+](C2OC(COP(=O)(O)OP(=O)(O)OP(=O)(O)O)C(O)C2O)c2nc(N)[nH]c(=O)c21',\n",
       " 'Nc1ncnc2c1ncn2C1OC(CSCCC(N)C(=O)O)C(O)C1O',\n",
       " 'NC(Cc1ccc(O)cc1)C(=O)O',\n",
       " 'CC(C)OCC1CO1',\n",
       " 'CC(=O)NC1C(O)CC(OC2C(O)C(CO)OC(OC(C(O)CO)C(O)C(O)C=O)C2O)(C(=O)O)OC1C(O)C(O)CO',\n",
       " 'CN1CCC(n2cc(-c3ccc(Oc4ccccc4)cc3)c3c(N)ncnc32)CC1',\n",
       " 'CCCCCn1cc(-c2ccccc2)nc1N',\n",
       " 'CCCCCCCCCC(=O)CC(=O)NC1CCOC1=O',\n",
       " 'CS(=O)(=O)c1ccc(Cl)c(-c2[nH]nc3nc(Oc4ccc(F)cc4F)ncc23)c1',\n",
       " 'CC(=O)NC(Cc1ccccc1)P(=O)(O)O',\n",
       " 'CCC(C)C(NC(=O)CNC(=O)C(CCC(N)=O)NC(=O)C1CCCN1C(=O)C(CC(=O)O)NC(=O)C(CCCNC(=N)N)NC(=O)C(NC(=O)C(NC(=O)C(N)CCCNC(=N)N)C(C)C)C(C)C)C(=O)NC(CCCNC(=N)N)C(=O)NC(C)C(=O)NC(Cc1c[nH]c2ccccc12)C(=O)NC(C(=O)NC(C)C(=O)NC(Cc1c[nH]c2ccccc12)C(=O)NC(CCCNC(=N)N)C(=O)NC(CC(N)=O)C(=O)NC(CCCNC(=N)N)C(=O)O)C(C)C',\n",
       " 'C[S+](CCC(N)C(=O)[O-])CC1OC(n2cnc3c(N)ncnc32)C(O)C1O',\n",
       " 'Cc1ncc([N+](=O)[O-])n1CCO',\n",
       " 'CC1(C)SC2C(NC(=O)C(N)c3ccccc3)C(=O)N2C1C(=O)O',\n",
       " 'COC(=O)C1C(OC(=O)c2ccccc2)CC2CCC1N2C',\n",
       " 'C=CC1=C(C)c2cc3[n-]c(cc4[n-]c(cc5nc(cc1n2)C(C)=C5C=C)c(C)c4CCC(=O)O)c(CCC(=O)O)c3C.[Cl-].[Fe+3]',\n",
       " 'COc1cc2c(c3oc(=O)c4c(c13)CCC4=O)C1(O)C=COC1O2',\n",
       " 'CC1=CC2Cc3[nH]c(=O)ccc3C3(C1)NCCCC23',\n",
       " 'NC(N)=NCCCC(N)C(=O)O',\n",
       " 'CCC(C)C(NC(=O)CN)C(=O)NC(C(=O)NC(CCC(=O)O)C(=O)NC(CCC(N)=O)C(=O)NC1CSSCC2NC(=O)C(C(C)CC)NC(=O)C(CO)NC(=O)C(C(C)O)NC(=O)C(CSSCC(NC(=O)C(CC(C)C)NC(=O)C(Cc3c[nH]cn3)NC(=O)C(CCC(N)=O)NC(=O)C(NC(=O)C(NC(=O)C(N)Cc3ccccc3)C(C)C)C(N)=O)C(=O)NCC(=O)NC(CO)C(=O)NC(Cc3c[nH]cn3)C(=O)NC(CC(C)C)C(=O)NC(C(C)C)C(=O)NC(CCC(=O)O)C(=O)NC(C)C(=O)NC(CC(C)C)C(=O)NC(Cc3ccc(O)cc3)C(=O)NC(CC(C)C)C(=O)NC(C(C)C)C(=O)NC(C(=O)NCC(=O)NC(CCC(=O)O)C(=O)NC(CCCNC(=N)N)C(=O)NCC(=O)NC(Cc3ccccc3)C(=O)NC(Cc3ccccc3)C(=O)NC(Cc3ccc(O)cc3)C(=O)NC(C(=O)N3CCCC3C(=O)NC(CCCCN)C(=O)NC(C(=O)O)C(C)O)C(C)O)CSSCC(C(=O)NC(CC(N)=O)C(=O)O)NC(=O)C(Cc3ccc(O)cc3)NC(=O)C(CC(N)=O)NC(=O)C(CCC(=O)O)NC(=O)C(CC(C)C)NC(=O)C(CCC(N)=O)NC(=O)C(Cc3ccc(O)cc3)NC(=O)C(CC(C)C)NC(=O)C(CO)NC2=O)NC1=O)C(C)C',\n",
       " 'O=C1OC(C(O)CO)C(O)=C1O',\n",
       " 'Nc1nc(N)nc(N)n1',\n",
       " 'COP(N)(=S)Oc1ccccc1C(=O)OC(C)C',\n",
       " 'O=c1[nH]c(=O)c2[nH]cnc2[nH]1',\n",
       " 'CC1(C)SC(C(NC(=O)C(N)c2ccc(O)cc2)C(=O)O)NC1C(=O)O',\n",
       " 'CSCCC(NC(C)=O)C(=O)NC(Cc1c[nH]c2ccccc12)C(=O)NC(CC(=O)O)C(=O)NC(Cc1ccccc1)C(=O)NC(CC(=O)O)C(=O)NC(CC(=O)O)C(=O)NC(CC(C)C)C(=O)NC(CC(N)=O)C(=O)NC(Cc1ccccc1)C(=O)NC(C(=O)NCC(=O)NC(CCSC)C(=O)N1CCCC1C(=O)N1CCCC1C(=O)NC(C)C(=O)NC(CC(=O)O)C(=O)NC(CCC(=O)O)C(=O)NC(CC(=O)O)C(=O)NC(Cc1ccc(O)cc1)C(=O)NC(CO)C(=O)N1CCCC1C(N)=O)C(C)O',\n",
       " 'NC(Cc1cnc[nH]1)C(=O)O',\n",
       " 'NC(=O)NCCCC(N)C(=O)O',\n",
       " 'NC(=O)c1ccc[n+](C2OC(COP(=O)([O-])OP(=O)(O)OCC3OC(n4cnc5c(N)ncnc54)C(O)C3O)C(O)C2O)c1',\n",
       " 'NC(=O)C1=CN(C2OC(COP(=O)(O)OP(=O)(O)OCC3OC(n4cnc5c(N)ncnc54)C(O)C3O)C(O)C2O)C=CC1',\n",
       " 'O=C(NC(CO)C(O)c1ccc([N+](=O)[O-])cc1)C(Cl)Cl',\n",
       " 'CCC(C)C(N=C(O)C(CO)N=C(O)C1CCCN1C(=O)C(C)N=C(O)CN=C(O)C(CC(C)C)N=C(O)C(CCCCN)N=C(O)C(CCCCN)N=C(O)C(CCSC)N=C(O)C(CCCNC(=N)N)N=C(O)C(Cc1c[nH]c2ccccc12)N=C(O)C(CCC(=N)O)N=C(O)C(Cc1c[nH]c2ccccc12)N=C(O)C(CCCNC(=N)N)N=C(O)C(CCCNC(=N)N)N=C(O)C(CS)N=C(O)C(CCCCN)N=C(O)C(N)Cc1ccccc1)C(O)=NC(C(O)=NC(CS)C(O)=NC(C(O)=NC(CCCNC(=N)N)C(O)=NC(CCCNC(=N)N)C(O)=NC(C)C(O)=NC(Cc1ccccc1)C(=O)O)C(C)C)C(C)O',\n",
       " 'CC1=C2N=C(C=C3N=C(C(C)=C4[N-]C(C(CC(N)=O)C4(C)CCC(=O)NCC(C)O)C4(C)N=C1C(CCC(N)=O)C4(C)CC(N)=O)C(CCC(N)=O)C3(C)C)C(CCC(N)=O)C2(C)CC(N)=O.[C-]#N.[C-]#N.[Co]',\n",
       " 'Nc1nc2nc[nH]c2c(=O)[nH]1',\n",
       " 'O=C1OC2(c3ccc(O)cc3Oc3cc(O)ccc32)c2ccccc21',\n",
       " 'CCCCCCCCC1CC(=O)NC(CC(N)=O)C(=O)NC(Cc2ccc(O)cc2)C(=O)NC(CC(N)=O)C(=O)N2CCCC2C(=O)NC(CCC(=O)O)C(=O)NC(CO)C(=O)NC(C(C)O)C(=O)N1',\n",
       " 'CC1c2cccc(O)c2C(O)=C2C(=O)C3(O)C(O)=C(C(N)=O)C(=O)C(N(C)C)C3C(O)C21',\n",
       " 'CCc1c(C)c2cc3nc(cc4nc(cc5c(CC)c(C)c(cc1[nH]2)n5C)C(C)=C4CCC(=O)O)C(CCC(=O)O)=C3C',\n",
       " 'C.C.C.CCN(CC)c1ccc(C=NN=C2c3cc(N(CC)CC)ccc3-c3ccc(N(CC)CC)cc32)c(OCC(O)CSc2ccc(Sc3ccc(SCC(O)COc4cc(N(CC)CC)ccc4C=NN=C4c5cc(N(CC)CC)ccc5-c5ccc(N(CC)CC)cc54)cc3)cc2)c1.CCN(CC)c1ccc(C=NN=C2c3cc(N(CC)CC)ccc3-c3ccc(N(CC)CC)cc32)c(OCC(O)CSc2nnc(SCC(O)COc3cc(N(CC)CC)ccc3C=NN=C3c4cc(N(CC)CC)ccc4-c4ccc(N(CC)CC)cc43)s2)c1.CCN(CC)c1ccc(C=NN=C2c3ccccc3-c3ccccc32)c(OCC(O)COc2ccc(C(C)(C)c3ccc(OCC(O)COc4cc(N(CC)CC)ccc4C=NN=C4c5ccccc5-c5ccccc54)cc3)cc2)c1',\n",
       " 'Nc1nc2c(ncn2C2OC(COP(=O)(O)OP(=O)(O)OP(=O)(O)O)C(O)C2O)c(=O)[nH]1',\n",
       " 'NCCO',\n",
       " 'CC(=O)OCC[N+](C)(C)C',\n",
       " 'CCC(C)C(NC(=O)C(C)NC(=O)CNC(=O)C(CCCCN)NC(=O)C(CC(N)=O)NC(=O)C(CO)NC(=O)CNC(=O)C(NC(=O)C(CC(=O)O)NC(=O)C(CCC(=O)O)NC(=O)C(C)NC(=O)C(Cc1ccccc1)NC(=O)C(Cc1ccccc1)NC(=O)C(NC(=O)C(CC(C)C)NC(=O)C(CCCCN)NC(=O)C(CCC(N)=O)NC(=O)C(Cc1c[nH]cn1)NC(=O)C(Cc1c[nH]cn1)NC(=O)C(NC(=O)C(CCC(=O)O)NC(=O)C(Cc1ccc(O)cc1)NC(=O)CNC(=O)C(CO)NC(=O)C(CC(=O)O)NC(=O)C(Cc1c[nH]cn1)NC(=O)C(CCCNC(=N)N)NC(=O)C(Cc1ccccc1)NC(=O)C(CCC(=O)O)NC(=O)C(C)NC(=O)C(N)CC(=O)O)C(C)C)C(C)C)C(C)C)C(=O)NC(C(=O)NCC(=O)NC(CC(C)C)C(=O)NC(CCSC)C(=O)NC(C(=O)NCC(=O)NCC(=O)NC(C(=O)NC(C(=O)NC(C(=O)NC(C)C(=O)O)C(C)CC)C(C)C)C(C)C)C(C)C)C(C)CC',\n",
       " 'O=C(O)Cc1ccccc1Nc1c(Cl)cccc1Cl',\n",
       " 'CCC(C)(c1ccc(O)cc1)c1ccc(O)cc1',\n",
       " 'NC(=O)OCC1N=C(N)N2CCC(O)(O)C23NC(N)=NC13',\n",
       " 'C=C1C(O)C2OC3(CCC(C=CC(C)C4CC(C)=CC5(OC(CC(C)(O)C(=O)O)CCC5O)O4)O3)CCC2OC1C(O)CC(C)C1OC2(CCCCO2)CCC1C',\n",
       " 'O=C(CO)NC1C(O)CC(O)(C(=O)O)OC1C(O)C(O)CO',\n",
       " 'CC12CCC(=O)C=C1CCC1C2C(O)CC2(C)C1CCC2(O)C(=O)CO',\n",
       " '[Cd]',\n",
       " '[Pd+2]',\n",
       " 'C=C(C=O)CC1CC(O)C2(C)OC3CC4OC5CC6(C)OC7(C)CCC8OC9CC%10(C)OC%11C(C)=CC(=O)OC%11CC%10OC9CC(C)C8OC7CC6OC5(C)CC=CC4OC3CC2O1',\n",
       " 'COc1cc2c(c3oc(=O)c4c(c13)CCC4=O)C1C=COC1O2',\n",
       " 'CC1(C)SC2C(NC(=O)Cc3ccccc3)C(=O)N2C1C(=O)O',\n",
       " 'CC(CCc1ccc(O)cc1)NCC(O)c1ccc(O)cc1',\n",
       " 'CC1=C(O)C(=O)C(C)O1',\n",
       " 'CC1CCCC(=O)CCCC=Cc2cc(O)cc(O)c2C(=O)O1',\n",
       " 'CCNc1nc(Cl)nc(NC(C)C)n1',\n",
       " 'CC1(C)SC2C(NC(=O)C(NC(=O)N3CCNC3=O)c3ccccc3)C(=O)N2C1C(=O)O',\n",
       " 'C=CCC1C=C(C)CC(C)CC(OC)C2OC(O)(C(=O)C(=O)N3CCCCC3C(=O)OC(C(C)=CC3CCC(O)C(OC)C3)C(C)C(O)CC1=O)C(C)CC2OC',\n",
       " 'Cc1cc(C)nc(NS(=O)(=O)c2ccc(N)cc2)n1',\n",
       " 'N#N',\n",
       " 'Nc1c(S(=O)(=O)O)cc(Nc2ccc(Nc3nc(Cl)nc(Nc4cccc(S(=O)(=O)O)c4)n3)c(S(=O)(=O)O)c2)c2c1C(=O)c1ccccc1C2=O',\n",
       " 'NCC1OC(OC2C(CO)OC(OC3C(O)C(N)CC(N)C3OC3OC(CO)C(O)CC3N)C2O)C(N)C(O)C1OC1OC(CO)C(O)C(O)C1O',\n",
       " 'CC(=O)NC(C=O)C(OC1OC(C)C(O)C(O)C1O)C(OC1OC(CO)C(O)C(OC2(C(=O)O)CC(O)C(NC(C)=O)C(C(O)C(O)CO)O2)C1O)C(O)CO',\n",
       " 'CSCCC(NC(=O)C(CC(C)C)NC(=O)CNC(=O)C(Cc1ccccc1)NC(=O)C(Cc1ccccc1)NC(=O)C(CCC(N)=O)NC(=O)C(CCC(N)=O)NC(=O)C1CCCN1C(=O)C(CCCCN)NC(=O)C1CCCN1C(=O)C(N)CCCN=C(N)N)C(N)=O',\n",
       " 'CCOc1ccc(-c2nc3ccc(-c4nc5ccc(N6CCN(C)CC6)cc5[nH]4)cc3[nH]2)cc1',\n",
       " 'CC1=NC(=Cc2cc(F)c(O)c(F)c2)C(=O)N1C',\n",
       " 'CC1=NC(=Cc2cc(F)c(O)c(F)c2)C(=O)N1CC(F)(F)F',\n",
       " 'CN1C(=Cc2cc[n+](CCC[N+](C)(C)C)c3ccccc23)Oc2ccccc21.[I-]',\n",
       " 'CN1C(=Cc2cc[n+](C)c3ccccc23)Sc2ccccc21.Cc1ccc(S(=O)(=O)[O-])cc1',\n",
       " 'NC(Cc1c[nH]c2ccc(O)cc12)C(=O)O',\n",
       " 'Cn1c(=CN=O)[nH]c(=Cc2cc(F)c(O)c(F)c2)c1=O',\n",
       " 'CCCCCCCCCCCCCCCCCCN1C(=CC=CC2=[N+](CCCCCCCCCCCCCCCCCC)c3ccccc3C2(C)C)C(C)(C)c2ccccc21.[O-][Cl+3]([O-])([O-])[O-]',\n",
       " 'CN(C)c1ccc2c(-c3ccccc3C(=O)[O-])c3ccc(=[N+](C)C)cc-3oc2c1',\n",
       " 'COc1cc(C=c2[nH]c(=CN=O)n(-c3ccc([N+](C)(C)C)cc3)c2=O)cc(OC)c1O.[I-]',\n",
       " 'COC(=O)C=CC1=NC(=Cc2cc(F)c(O)c(F)c2)C(=O)N1C',\n",
       " 'CN1C(=O)C(=Cc2ccc(N(C)CCO)cc2)N=C1C=Cc1ccccc1',\n",
       " 'N#CC(=Cc1cc2c3c(c1)CCCN3CCC2)C(=O)NCCOCCN',\n",
       " 'Nc1ccc(CC(N)C(=O)O)cc1',\n",
       " 'CCN(CC)c1ccc2c(-c3ccc(S(=O)(=O)NCCC(=O)NCCCCC(NC(=O)CCNS(=O)(=O)c4ccc(-c5c6ccc(=[N+](CC)CC)cc-6oc6cc(N(CC)CC)ccc56)c(S(=O)(=O)[O-])c4)C(=O)NCc4cn(CCOCCOCCOCCNC(=O)CCCCC5SCC6NC(=O)NC65)nn4)cc3S(=O)(=O)[O-])c3ccc(=[N+](CC)CC)cc-3oc2c1',\n",
       " 'NC(Cc1ccccc1)C(=O)O',\n",
       " 'Clc1ccc(-c2ccc(Cl)c(Cl)c2)cc1Cl',\n",
       " 'Nc1ncnc2c1ncn2C1OC(COP(=O)(O)OP(=O)(O)O)C(O)C1O',\n",
       " 'COP(=O)(OC)OC=C(Cl)Cl',\n",
       " 'O=[As]O[As]=O',\n",
       " 'COC(=O)C(Cc1ccccc1)NC(=O)C(N)CC(=O)O',\n",
       " 'CC12CCC3c4ccc(O)cc4CCC3C1CCC2O',\n",
       " 'Nc1ccn(C2OC3COP(=O)(O)OC3C2O)c(=O)n1',\n",
       " 'Nc1nc2c(ncn2C2OC3COP(=O)([O-])OC3C2O)c(=O)[nH]1.[Na+]',\n",
       " 'CC(=O)NC1C(O)OC(CO)C(O)C1O',\n",
       " '[Co]',\n",
       " 'CC1=C2N=C(C=C3N=C(C(C)=C4[N-]C(C)(C5N=C1C(C)(CCC(=O)NCC(C)OP(=O)([O-])OC1C(CO)OC(n6cnc7cc(C)c(C)cc76)C1O)C5CC(N)=O)C(C)(CC(N)=O)C4CCC(N)=O)C(C)(CC(N)=O)C3CCC(N)=O)C(C)(C)C2CCC(N)=O.[C-]#N.[Co+3]',\n",
       " 'OCC1(O)OCC(O)C(O)C1O',\n",
       " 'OCC1OC(O)C(O)C(O)C1O',\n",
       " 'Cc1cc2nc3c(=O)nc([O-])nc-3n(CC(O)C(O)C(O)COP(=O)([O-])[O-])c2cc1C',\n",
       " 'CNC(C)C1CCC(N)C(OC2C(N)CC(N)C(OC3OCC(C)(O)C(NC)C3O)C2O)O1',\n",
       " '[Hg+2]',\n",
       " 'CCCCCCCCCCCCCC(=O)OC(CCCCCCCCCCC)CC(=O)OC1C(NC(=O)CC(CCCCCCCCCCC)OC(=O)CCCCCCCCCCC)C(OCC2OC(OP(=O)(O)O)C(NC(=O)CC(O)CCCCCCCCCCC)C(OC(=O)CC(O)CCCCCCCCCCC)C2O)OC(COC2(C(=O)O)CC(OC3(C(=O)O)CC(OC4(C(=O)O)CC(OP(=O)(O)OCCN)C(O)C(C(O)CO)O4)C(O)C(C(O)CO)O3)C(OC3OC(C(O)CO)C(OP(=O)(O)OP(=O)(O)OCCN)C(OC4OC(C(O)COC5OC(C(O)CO)C(OP(=O)(O)O)C(O)C5O)C(O)C(OC5OC(COC6OC(CO)C(O)C(O)C6O)C(O)C(OC6OC(CO)C(O)C(O)C6OC6OC(CO)C(O)C(O)C6OC6OC(CO)C(O)C(O)C6NC(C)=O)C5O)C4O)C3O)C(C(O)CO)O2)C1OP(=O)(O)O',\n",
       " 'Cc1cc(Cc2ccc(N)c(C)c2)ccc1N',\n",
       " 'C=C1C(=O)NC(C)C(=O)NC(CC(C)C)C(=O)NC(C(=O)O)C(C)C(=O)NC(C)C(=O)NC(C=CC(C)=CC(C)C(Cc2ccccc2)OC)C(C)C(=O)NC(C(=O)O)CCC(=O)N1C',\n",
       " 'C=C1C(=O)NC(C)C(=O)NC(CC(C)C)C(=O)NC(C(=O)O)C(C)C(=O)NC(CCCN=C(N)N)C(=O)NC(C=CC(C)=CC(C)C(Cc2ccccc2)OC)C(C)C(=O)NC(C(=O)O)CCC(=O)N1C',\n",
       " 'C=C1C(=O)NC(C)C(=O)NC(Cc2ccc(O)cc2)C(=O)NC(C(=O)O)C(C)C(=O)NC(CCCN=C(N)N)C(=O)NC(C=CC(C)=CC(C)C(Cc2ccccc2)OC)C(C)C(=O)NC(C(=O)O)CCC(=O)N1C',\n",
       " '[Mn]',\n",
       " 'C=C(CC=C(C)CCC=C(C)C)CCC(C)(C)C=CCCC(C)=CCOC(COP(=O)(O)OC1OC(C(=O)O)C(C)(O)C(OC(N)=O)C1OC1OC(COC2OC(CO)C(O)C(O)C2O)C(OC2OC(C)C(OC3OC(C(=O)NC4=C(O)CCC4=O)C(O)C(O)C3O)C(O)C2NC(C)=O)C(O)C1NC(C)=O)C(=O)O',\n",
       " '[Na]',\n",
       " '[Ni]',\n",
       " 'CCC1=C(C)c2cc3[nH]c(cc4nc(cc5c(CCC(=O)O)c(C)c(cc1n2)n5C)C(CCC(=O)O)=C4C)c(C)c3CC',\n",
       " 'CNC(=O)CSP(=O)(OC)OC',\n",
       " '[Pb+2]',\n",
       " 'CCOP(=S)(OCC)SCSCC',\n",
       " 'Oc1ccc(Cl)cc1-c1cc(Cl)c(Cl)c(Cl)c1Cl',\n",
       " 'Oc1c(Cl)cc(-c2cc(Cl)ccc2Cl)cc1Cl',\n",
       " 'CCCSP(=O)(OCC)Oc1ccc(Br)cc1Cl',\n",
       " 'C=CC1=C(C)C2=NC1=CC1=NC(=CC3=C(C)C4=C(O)CC(=C5NC(=C2)C(C)C5CCC(=O)O)C4=N3)C(CC)=C1C',\n",
       " 'Nc1c(N=Nc2ccc(Nc3nc(Cl)nc(Nc4cccc(S(=O)(=O)[O-])c4)n3)cc2S(=O)(=O)[O-])c(S(=O)(=O)[O-])cc2cc(S(=O)(=O)[O-])c(N=Nc3ccc(Nc4nc(Cl)nc(Nc5cccc(S(=O)(=O)[O-])c5)n4)cc3S(=O)(=O)[O-])c(O)c12.[Na+].[Na+].[Na+].[Na+].[Na+].[Na+]',\n",
       " 'CC(=O)NC1C(O)CC(OCC2OC(OC(C(O)CO)C(O)C(O)C=O)C(O)C(O)C2O)(C(=O)O)OC1C(O)C(O)CO',\n",
       " 'CN(C)C1C(=O)C(C(N)=O)=C(O)C2(O)C(=O)C3=C(O)c4c(O)cccc4C(C)(O)C3CC12.Cl',\n",
       " 'CC(C)C(N)C(=O)O',\n",
       " '[Zn]',\n",
       " 'CCCCCc1cc(O)c2c(c1)OC(C)(C)C1CCC(C)=CC21',\n",
       " 'CC1(C)C(C(=O)c2cn(CCCCCF)c3ccccc23)C1(C)C',\n",
       " 'CCCC(C(=O)c1ccc2c(c1)OCO2)N1CCCC1',\n",
       " 'O=C(O)C(F)(F)C(F)(F)C(F)(F)C(F)(F)C(F)(F)C(F)(F)C(F)(F)F',\n",
       " 'O=C(O)C(F)(F)C(F)(F)C(F)(F)C(F)(F)C(F)(F)C(F)(F)F',\n",
       " 'O=S(=O)(O)C(F)(F)C(F)(F)C(F)(F)C(F)(F)C(F)(F)C(F)(F)F',\n",
       " 'CC1Cc2ccc(C(=O)NC(Cc3ccccc3)C(=O)O)c(O)c2C(=O)O1',\n",
       " 'CC(=O)CC(c1ccccc1)c1c(O)c2ccccc2oc1=O',\n",
       " 'CC1=C2C(=COC(C)C2C)C(=O)C(C(=O)O)=C1O',\n",
       " 'CC(=O)NC1C(OC2C(CO)OC(O)C(NC(C)=O)C2OC(C)C(=O)NC(C)C(=O)NC(CCC(N)=O)C(=O)NC(CCCC(N)C(=O)O)C(=O)NC(C)C(=O)NC(C)C(=O)O)OC(CO)C(O)C1O',\n",
       " 'NCCCCC(N)C(=O)O',\n",
       " 'CN1C(=O)C(=Cc2cc(F)c(O)c(F)c2)N=C1C(F)(F)F',\n",
       " 'CCCCOC(=O)c1ccccc1C(=O)OCCCC',\n",
       " 'CC(=O)C1=CCCC2CCC1N2',\n",
       " 'O=c1[nH]c(NCc2ccccc2)nc2nc[nH]c12',\n",
       " 'CCC(C)n1c(=O)[nH]c(C)c(Br)c1=O',\n",
       " 'CN1CC2CC1CN2c1cc2c(cc1F)c(=O)c(C(=O)O)cn2C1CC1',\n",
       " '[Pd]',\n",
       " 'CC(=O)C1CCC2C3CCC4=CC(=O)CCC4(C)C3CCC12C',\n",
       " 'CC(=O)OCC12CC(OC(=O)CC(C)C)C(C)=CC1OC1C(O)C(OC(C)=O)C2(C)C12CO2',\n",
       " 'CN(CCO)c1ccc(C=C(C#N)c2ccc(C#N)cc2)cc1',\n",
       " 'Nc1ncnc2c1ncn2[C@@H]1O[C@H](COP(=O)(O)O)[C@@H](O)[C@H]1O',\n",
       " 'CN1COCN(Cc2cnc(Cl)s2)/C1=N\\\\[N+](=O)[O-]',\n",
       " 'C[C@]12CC[C@H]3[C@@H](CCC4=CC(=O)CC[C@@]43C)[C@@H]1CC[C@@H]2O',\n",
       " 'Nc1ccc(S(=O)(=O)Nc2cnc3ccccc3n2)cc1',\n",
       " 'N[C@@H](CCS)C(=O)O',\n",
       " 'NC(N)=O',\n",
       " 'CC(=O)Nc1ccc(S(N)(=O)=O)cc1',\n",
       " 'C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C@@H]2O',\n",
       " 'COC(=O)[C@H]1[C@@H](OC(=O)c2ccccc2)C[C@@H]2CC[C@H]1N2C',\n",
       " 'CN1C(=O)c2ccn(C)c2C1=O',\n",
       " 'NCCc1cnc[nH]1',\n",
       " 'Nc1ccn(C2OC(COP(=O)(O)OP(=O)(O)OP(=O)(O)O)C(O)C2O)c(=O)n1',\n",
       " 'O=c1ccn(C2OC(COP(=O)(O)OP(=O)(O)OP(=O)(O)O)C(O)C2O)c(=O)[nH]1',\n",
       " 'Nc1ncnc2c1ncn2C1OC(CO)C(OP(=O)(O)O)C1O',\n",
       " 'Nc1ncnc2c1ncn2[C@H]1O[C@H](CO)[C@@H](O)[C@H]1O',\n",
       " 'Nc1ncnc2c1nc(Br)n2C1OC(CO)C(O)C1O',\n",
       " '[N-]=[N+]=Nc1nc2c(N)ncnc2n1C1OC(CO)C(O)C1O',\n",
       " 'Nc1ncnc2c1ccn2C1OC(CO)C(O)C1O',\n",
       " 'CC1OC(n2cnc3c(N)ncnc32)CC1O',\n",
       " 'Nc1ncnc2c1ncn2C1OC(CO)CC1O',\n",
       " 'Nc1ncnc2c1ncn2C1CCC(CO)O1',\n",
       " 'Nc1ncnc2c1ncn2C1OC(CO)C2OP(=O)(O)OC21',\n",
       " 'Nc1ncnc2c1ncn2C1OC(CO)C(O)C1OP(=O)(O)O',\n",
       " 'COC1C(O)C(CO)OC1n1cnc2c(N)ncnc21',\n",
       " 'Cn1cnc(=N)c2[nH]cnc21',\n",
       " 'COC1C(CO)OC(n2cnc3c(N)ncnc32)C1O',\n",
       " 'Cc1nc(N)c2[nH]cnc2n1',\n",
       " 'Cn1cnc2c(ncn2C2OC(CO)C(O)C2O)c1=N',\n",
       " 'Nc1ncnc2c1ncn2C1CC(O)C(COP(=O)(O)OP(=O)(O)OP(=O)(O)O)O1',\n",
       " 'O=CC(O)C(O)C(O)CO',\n",
       " 'CNc1ncnc2c1ncn2C1OC(CO)C(O)C1O',\n",
       " 'Nc1ncc2ncn(C3OC(CO)C(O)C3O)c2n1',\n",
       " 'OCC1OC(n2cnc3cncnc32)C(O)C1O',\n",
       " 'O=c1[nH]cnc2c1ncn2C1OC(CO)C(O)C1O',\n",
       " 'CN[C@@H]1[C@H](O[C@H]2[C@H](O[C@H]3[C@H](O)[C@@H](O)[C@H](N=C(N)N)[C@@H](O)[C@@H]3N=C(N)N)O[C@@H](C)[C@]2(O)C=O)O[C@@H](CO)[C@H](O)[C@H]1O',\n",
       " 'COC1[C@@H](C)[C@@](C)(O)O[C@H]([C@H]2C[C@H](C)[C@H]([C@]3(C)CC[C@H]([C@]4(C)CC[C@]5(C[C@H](OC)[C@@H](C)[C@@H]([C@@H](C)[C@H]6O[C@@](O)([C@H](C)C(=O)O)[C@H](C)[C@@H](OC)[C@H]6C)O5)O4)O3)O2)[C@H]1C',\n",
       " 'O=C1C=CC2C(=C1)Oc1cc(O)ccc1C21OC(=O)c2ccccc21',\n",
       " 'NCCc1c[nH]c2ccc(O)cc12',\n",
       " 'CCc1c(C)c2cc3[nH]c(cc4nc(cc5nc(cc1[nH]2)C(C)=C5CCC(=O)O)C(CCC(=O)O)=C4C)c(C)c3CC',\n",
       " 'CCc1c(C)c2cc3[n-]c(cc4nc(cc5nc(cc1[n-]2)C(C)=C5CCC(=O)O)C(CCC(=O)O)=C4C)c(C)c3CC.O.[Fe+3]',\n",
       " 'CCc1c(C)c2cc3[n-]c(cc4nc(cc5nc(cc1[n-]2)C(C)=C5CCC(=O)O)C(CCC(=O)O)=C4C)c(C)c3CC.[Ni+2]',\n",
       " 'CCc1c(C)c2cc3[n-]c(cc4nc(cc5nc(cc1[n-]2)C(C)=C5CCC(=O)O)C(CCC(=O)O)=C4C)c(C)c3CC.[Zn+2]',\n",
       " 'O=c1[nH]cnc2nc[nH]c12',\n",
       " 'CC1(C)S[C@@H]2[C@H](NC(=O)Cc3ccccc3)C(=O)N2[C@H]1C(=O)[O-]',\n",
       " 'CCC1OC(=O)C(C)C(OC2CC(C)(OC)C(O)C(C)O2)C(C)C(OC2OC(C)CC(N(C)C)C2O)C(C)(O)CC(C)C(=O)C(C)C(O)C1(C)O',\n",
       " 'CNC(C)Cc1ccccc1',\n",
       " 'CC(=O)[C@H]1CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@]4(C)[C@H]3CC[C@]12C',\n",
       " 'N[C@@H](Cc1cc([131I])c(Oc2cc([131I])c(O)c([131I])c2)c([131I])c1)C(=O)O',\n",
       " 'COC(=O)[C@@H](N)CCCNC(=N)N[N+](=O)[O-]',\n",
       " 'N[C@@H](CS)C(=O)O',\n",
       " 'CC1(C)S[C@@H]2[C@H](NC(=O)[C@H](N)c3ccccc3)C(=O)N2[C@H]1C(=O)O',\n",
       " 'CS(=O)(=O)c1ccc([C@@H](O)[C@@H](CF)NC(=O)C(Cl)Cl)cc1',\n",
       " 'COc1ccc(Cc2nccc3cc(OC)c(OC)cc23)cc1OC',\n",
       " 'C=C[C@H]1CN2CC[C@H]1C[C@H]2[C@H](O)c1ccnc2ccc(OC)cc12',\n",
       " 'Nc1ncnc2c1nnn2C1COC(COP(=O)(O)OP(=O)(O)OP(=O)(O)O)C1',\n",
       " 'Cc1cc2nc3[nH]c(=O)[nH]c(=O)c3nc2cc1C',\n",
       " 'NC(=O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)([O-])O)[C@@H](O)[C@H]2O)c1',\n",
       " 'NC(=O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)([O-])OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](O)[C@@H]3O)[C@@H](O)[C@H]2O)c1',\n",
       " 'NC(=O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)([O-])OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](OP(=O)(O)O)[C@@H]3O)[C@@H](O)[C@H]2O)c1',\n",
       " 'NC(=O)c1cccnc1',\n",
       " 'C[n+]1cccc(C(N)=O)c1',\n",
       " 'O=C(O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)(O)O)[C@@H](O)[C@H]2O)c1',\n",
       " 'NC(=S)c1ccc[n+]([C@@H]2O[C@H](COP(=O)(O)OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](O)[C@@H]3O)[C@@H](O)[C@H]2[O-])c1',\n",
       " 'Cn1ncc(-c2nc(N[C@H]3CC[C@H](N)CC3)ncc2Cl)c1CC1CC1',\n",
       " 'NC(CCS)C(=O)O',\n",
       " 'CNCC(=O)O',\n",
       " 'CCCC[C@@H](C)[C@@H](OC(=O)C[C@H](CC(=O)O)C(=O)O)[C@@H](OC(=O)C[C@H](CC(=O)O)C(=O)O)[C@@H](C)C[C@H](O)CCCC[C@@H](O)C[C@H](O)[C@H](C)N',\n",
       " 'COc1cc(NS(=O)(=O)c2ccc(N)cc2)nc(OC)n1',\n",
       " 'CC(O)C(=O)O.O=C(O)COOCCO',\n",
       " 'CC(Cn1cnc2c(N)ncnc21)OCP(=O)(O)O',\n",
       " 'Clc1ccc(C(c2ccccc2Cl)C(Cl)(Cl)Cl)cc1',\n",
       " 'O=C(N[C@H](CO)[C@H](O)c1ccc([N+](=O)[O-])cc1)C(Cl)Cl',\n",
       " 'COc1ccc2c3c1O[C@H]1[C@@H](O)C=C[C@H]4[C@@H](C2)N(C)CC[C@@]341',\n",
       " 'CN1CCC23c4c5ccc(O)c4OC2C(O)C=CC3C1C5',\n",
       " 'CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C3C(=O)c4c(O)cccc4[C@@](C)(O)[C@H]3[C@H](O)[C@@H]12',\n",
       " 'C[C@H](CCC(=O)O)[C@H]1CC[C@H]2[C@@H]3[C@H](O)C[C@@H]4C[C@H](O)CC[C@]4(C)[C@H]3C[C@H](O)[C@]12C',\n",
       " 'CC(=O)O[C@@]12CO[C@@H]1C[C@H](O)[C@@]1(C)C(=O)[C@H](O)C3=C(C)[C@@H](OC(=O)[C@H](O)[C@@H](NC(=O)OC(C)(C)C)c4ccccc4)C[C@@](O)([C@@H](OC(=O)c4ccccc4)[C@H]21)C3(C)C.O.O.O',\n",
       " 'CC1(C)[C@@H](O[C@@H]2OC[C@H](O[C@@H]3OC[C@@H](O)[C@H](O)[C@H]3O)[C@H](O[C@H]3O[C@H](CO)[C@@H](O)[C@H](O)[C@H]3O)[C@H]2O[C@@H]2O[C@H](CO)[C@@H](O)[C@H](O)[C@H]2O[C@H]2O[C@H](CO)[C@@H](O)[C@H](O)[C@H]2O)CC[C@]2(C)[C@H]3CCC45OCC6(CC[C@@](C)(C=O)C[C@@H]64)[C@H](O)C[C@@]5(C)[C@]3(C)CC[C@@H]12',\n",
       " 'Clc1ccc(-c2cc(Cl)c(Cl)cc2Cl)c(Cl)c1',\n",
       " 'C/C(=N\\\\C#N)N(C)Cc1ccc(Cl)nc1',\n",
       " 'NC(=O)CF',\n",
       " 'COP(=O)(NC(C)=O)SC',\n",
       " 'CCOP(=O)(Sc1ccccc1)Sc1ccccc1',\n",
       " 'CC(C)OP(=O)(OC(C)C)SCc1ccccc1',\n",
       " 'Nc1ccc(Cc2ccc(N)cc2)cc1',\n",
       " 'CCN1CCN(c2cc3c(cc2F)c(=O)c(C(=O)O)cn3C2CC2)CC1',\n",
       " 'C[C@@H]1Cc2c(Cl)cc(C(=O)N[C@@H](Cc3ccccc3)C(=O)O)c(O)c2C(=O)O1',\n",
       " 'NC[C@H]1O[C@H](O[C@H]2[C@H](O)[C@@H](O[C@H]3O[C@H](CO)[C@@H](O)[C@H](N)[C@H]3O)[C@H](N)C[C@@H]2N)[C@H](O)[C@@H](O)[C@@H]1O',\n",
       " 'CC(COCCO)OCCO',\n",
       " 'COc1cc2c(c3oc(=O)c4c(c13)CCC4=O)[C@@H]1C=CO[C@@H]1O2',\n",
       " 'C[C@]12CC[C@H](OS(=O)(=O)O)CC1=CC[C@@H]1[C@@H]2CC[C@]2(C)C(=O)CC[C@@H]12',\n",
       " 'C[C@]12CC[C@H]3[C@@H](CCC4=CC(=O)CC[C@@H]43)[C@@H]1CC[C@@H]2O',\n",
       " 'C=C(CC=C(C)CCC=C(C)C)CCC(C)(C)C=CCCC(C)=CCOC(COP(=O)(O)OC1OC(C(N)=O)C(O)C(OC(N)=O)C1OC1OC(COC2OC(CO)C(O)C(O)C2O)C(OC2OC(C)C(OC3OC(C(=O)NC4=C(O)CCC4=O)C(O)C(O)C3O)C(O)C2NC(C)=O)C(O)C1NC(C)=O)C(=O)O',\n",
       " 'COc1cc2c(c3oc(=O)c4c(c13)CCC4=O)[C@]1(O)C=CO[C@@H]1O2',\n",
       " 'CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C3C(=O)c4c(O)cccc4[C@@](C)(O)[C@H]3C[C@@H]12',\n",
       " 'CC(=O)NC1C(OC2C(CO)OC(O)C(N)C2O)OC(CO)C(OC2OC(CO)C(O)C(O)C2N)C1O',\n",
       " 'COCCOCCOCCOCCOCCOCCOCCOCCOCCOCCOCCOCCNC(N)CNCCN(CCNCCN(CCN)CCN)CCN(CCNCCN)CCN(CCN)CCN',\n",
       " 'CN(Cc1cnc2nc(N)nc(N)c2n1)c1ccc(C(=O)NC(CCC(=O)O)C(=O)O)cc1',\n",
       " 'CCOP(=S)(OCC)ON=C(C#N)c1ccccc1',\n",
       " 'CC[C@H]1OC(=O)[C@H](C)[C@@H](OC2CC(C)(OC)C(O)C(C)O2)[C@H](C)[C@@H](OC2OC(C)CC(N(C)C)C2O)[C@](C)(O)C[C@@H](C)/C(=N\\\\OCOCCOC)[C@H](C)[C@@H](O)[C@]1(C)O',\n",
       " 'CC(C)Cc1ccc([C@@H](C)C(=O)O)cc1',\n",
       " 'CC(C)Cc1ccc([C@H](C)C(=O)O)cc1',\n",
       " 'COc1ccc(NS(=O)(=O)c2ccc(N)cc2)nn1',\n",
       " 'COc1cnc(NS(=O)(=O)c2ccc(N)cc2)nc1',\n",
       " 'Nc1ccc(S(=O)(=O)Nc2ccc(Cl)nn2)cc1',\n",
       " 'Nc1ccc(S(=O)(=O)Nc2ccccn2)cc1',\n",
       " 'NC[C@@H]1O[C@H](O[C@H]2[C@@H](O)[C@H](O[C@@H]3[C@@H](O)[C@H](N)C[C@H](N)[C@H]3O[C@H]3O[C@H](CN)[C@@H](O)[C@H](O)[C@H]3N)O[C@@H]2CO)[C@H](N)[C@@H](O)[C@@H]1O',\n",
       " 'CN[C@@H]1[C@H](O[C@H]2[C@H](O[C@H]3[C@H](O)[C@@H](O)[C@H](N=C(N)N)[C@@H](O)[C@@H]3N=C(N)N)O[C@@H](C)[C@]2(O)CO)O[C@@H](CO)[C@H](O)[C@H]1O',\n",
       " 'NC[C@H]1O[C@H](O[C@H]2[C@H](O)[C@@H](O[C@H]3O[C@H](CO)[C@@H](O)[C@H](N)[C@H]3O)[C@H](N)C[C@@H]2N)[C@H](N)C[C@@H]1O',\n",
       " 'CN[C@@H]1[C@H](O)[C@H](NC)[C@H]2O[C@@]3(O)C(=O)C[C@@H](C)O[C@H]3O[C@@H]2[C@H]1O',\n",
       " 'CN[C@@H]1[C@@H](O[C@H]2O[C@H](CO)[C@@H](N)[C@H](O)[C@H]2O)O[C@H]2C[C@@H](N)[C@@H](O[C@H]3[C@H](O)[C@@H](O)[C@H](N)C[C@@H]3N)O[C@@H]2[C@@H]1O',\n",
       " 'NC[C@@H]1O[C@H](O[C@H]2[C@@H](O)[C@H](O[C@@H]3[C@@H](O)[C@H](N)C[C@H](N)[C@H]3O[C@H]3O[C@H](CO)[C@@H](O)[C@H](O)[C@H]3N)O[C@@H]2CO)[C@H](N)[C@@H](O)[C@@H]1O',\n",
       " 'NCC[C@H](O)C(=O)N[C@@H]1C[C@H](N)[C@@H](O[C@H]2O[C@H](CN)[C@@H](O)[C@H](O)[C@H]2O)[C@H](O)[C@H]1O[C@H]1O[C@H](CO)[C@@H](O)[C@H](N)[C@H]1O',\n",
       " 'O=C(O)c1cn(C2CC2)c2cc(N3CCNCC3)c(F)cc2c1=O',\n",
       " 'C[C@H]1CCCC(=O)CCC/C=C/c2cc(O)cc(O)c2C(=O)O1',\n",
       " 'C=C1[C@@H](O)[C@@H]2O[C@]3(CC[C@H](/C=C/[C@@H](C)[C@@H]4CC(C)=C[C@@]5(O[C@H](C[C@@](C)(O)C(=O)O)CC[C@H]5O)O4)O3)CC[C@H]2O[C@@H]1[C@@H](O)C[C@H](C)[C@H]1O[C@@]2(CCCCO2)CC[C@H]1C',\n",
       " 'C=C1C(O)C2OC3(CCC(/C=C/C(C)C4CC(C)=CC5(OC(CC(C)(O)C(=O)O)CCC5O)O4)O3)CCC2OC1C(O)CC(C)C1OC2(CCC1C)OCCCC2C',\n",
       " 'C=C1[C@@H](O)[C@@H]2O[C@]3(CC[C@H](/C=C/[C@@H](C)[C@@H]4CC(C)=C[C@@]5(O[C@H](C[C@@](C)(O)C(=O)O)CC[C@H]5O)O4)O3)CC[C@H]2O[C@@H]1[C@@H](O)C[C@H](C)[C@@H]1CCC[C@@]2(OCCC[C@H]2C)O1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aug['canonical_smiles'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cfb9460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4578\n",
       "1    1922\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aug['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe755ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_aug['sequence'].apply(len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e040a4",
   "metadata": {},
   "source": [
    "## Sequence encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf11e5d",
   "metadata": {},
   "source": [
    "### One-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "036ed717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def onehot_with_type_bit(seqs, types, max_len=216):\n",
    "    if len(seqs) != len(types):\n",
    "        raise ValueError(\"seqs и types must be the same length\")\n",
    "\n",
    "    alphabet = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "    N = len(seqs)\n",
    "    out = np.zeros((N, max_len*4 + 1), dtype=np.float64)\n",
    "\n",
    "    for i, (s, t) in enumerate(zip(seqs, types)):\n",
    "        d = 1.0 if str(t).strip().upper() == \"RNA\" else 0.0\n",
    "        raw = (s or \"\").upper().replace(\"U\", \"T\")\n",
    "        raw = \"\".join(ch for ch in raw if ch in alphabet)\n",
    "        raw = raw[:max_len]\n",
    "        for j, ch in enumerate(raw):\n",
    "            out[i, j*4 + alphabet[ch]] = 1.0\n",
    "        out[i, -1] = d\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fb8414",
   "metadata": {},
   "source": [
    "### Kmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5309140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kmer_freq_with_type_bit(seqs, types, k=6):\n",
    "    if len(seqs) != len(types):\n",
    "        raise ValueError(\"seqs и types must be the same length\")\n",
    "\n",
    "    vocab = [''.join(p) for p in product('ACGT', repeat=k)]\n",
    "    vec = CountVectorizer(analyzer='char', ngram_range=(k, k), lowercase=False, vocabulary=vocab)\n",
    "\n",
    "    seqs_norm = [(s or \"\").upper().replace(\"U\", \"T\") for s in seqs]\n",
    "    X = vec.fit_transform(seqs_norm).astype(np.float64).toarray()\n",
    "\n",
    "    row_sum = X.sum(axis=1, keepdims=True)\n",
    "    row_sum[row_sum == 0] = 1.0\n",
    "    X = X / row_sum\n",
    "\n",
    "    d = (np.array([1.0 if str(t).upper() == \"RNA\" else 0.0 for t in types], dtype=np.float64)).reshape(-1, 1)\n",
    "    return np.concatenate([X, d], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b66619",
   "metadata": {},
   "source": [
    "### Pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e9b9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e580950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def gena_embed(seqs, types,\n",
    "               model_name='AIRI-Institute/gena-lm-bert-base-t2t-multi', max_len=216, batch_size=64):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name, output_hidden_states=True, trust_remote_code=True).to('cpu')\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    out = []\n",
    "    for i in range(0, len(seqs), batch_size):\n",
    "        batch = [(s or \"\").upper().replace(\"U\",\"T\") for s in seqs[i:i+batch_size]]\n",
    "        enc = tokenizer(batch, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\").to(device)\n",
    "        h = model(**enc).hidden_states[-1]                 \n",
    "        m = enc[\"attention_mask\"].unsqueeze(-1)           \n",
    "        out.append(((h * m).sum(1) / m.sum(1).clamp(min=1)).cpu().numpy())\n",
    "    E = np.vstack(out)\n",
    "    d = (np.array([1.0 if str(t).upper() == \"RNA\" else 0.0 for t in types], dtype=np.float64)).reshape(-1, 1)\n",
    "    return np.concatenate([E, d], axis=1)                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a777b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65990577",
   "metadata": {},
   "source": [
    "## Molecule encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc8fc0",
   "metadata": {},
   "source": [
    "### Morgan FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d8efe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morgan_fp(smiles_list, n_bits=2048, radius=2, counts=False):\n",
    "    X = np.zeros((len(smiles_list), n_bits), dtype=np.int32 if counts else np.uint8)\n",
    "    gen = rfg.GetMorganGenerator(radius=radius, fpSize=n_bits)\n",
    "\n",
    "    for i, smi in enumerate(smiles_list):\n",
    "        mol = Chem.MolFromSmiles(str(smi) if smi is not None else \"\")\n",
    "        if mol is None:\n",
    "            continue\n",
    "        if counts:\n",
    "            fp = gen.GetCountFingerprint(mol)  \n",
    "            for idx, val in fp.GetNonzeroElements().items():\n",
    "                if idx < n_bits:\n",
    "                    X[i, idx] = val\n",
    "        else:\n",
    "            fp = gen.GetFingerprint(mol)      \n",
    "            DataStructs.ConvertToNumpyArray(fp, X[i])\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78f0d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "smileses = ['Nc1c(S(=O)(=O)O)cc(Nc2ccc(Nc3nc(Cl)nc(Nc4ccccc4S(=O)(=O)O)n3)c(S(=O)(=O)O)c2)c2c1C(=O)c1ccccc1C2=O',\n",
    " 'Nc1c(S(=O)(=O)O)cc(Nc2ccc(S(=O)(=O)O)c(Nc3nc(Cl)nc(Cl)n3)c2)c2c1C(=O)c1ccccc1C2=O',\n",
    " 'Nc1ncnc2c1ncn2C1OC(COP(=O)(O)OP(=O)(O)OP(=O)(O)O)C(O)C1O',\n",
    " 'Nc1ncnc2c1ncn2C1OC(COP(=O)(O)O)C(O)C1O',\n",
    " 'Cc1cc2nc3c(=O)[nH]c(=O)nc-3n(CC(O)C(O)C(O)COP(=O)(O)OP(=O)(O)OCC3OC(n4cnc5c(N)ncnc54)C(O)C3O)c2cc1C',\n",
    " 'Cc1cc2nc3c(=O)[nH]c(=O)nc-3n(CC(O)C(O)C(O)COP(=O)(O)O)c2cc1C',\n",
    " 'Nc1ncnc2c1ncn2C1OC(CO)C(O)C1O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "553a2e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, ..., 0, 0, 0],\n",
       "       [0, 2, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 3, 0, ..., 0, 0, 0],\n",
       "       [0, 3, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], shape=(7, 2048), dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morgan_fp(smileses, counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90f2b70",
   "metadata": {},
   "source": [
    "### MACCS FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd17f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maccs_fp(smiles_list):\n",
    "    X = np.zeros((len(smiles_list), 167), dtype=np.uint8)\n",
    "    for i, smi in enumerate(smiles_list):\n",
    "        mol = Chem.MolFromSmiles(str(smi) if smi is not None else \"\")\n",
    "        if mol is None:\n",
    "            continue\n",
    "        bv = MACCSkeys.GenMACCSKeys(mol)\n",
    "        arr = np.zeros((bv.GetNumBits(),), dtype=np.int8)\n",
    "        DataStructs.ConvertToNumpyArray(bv, arr)\n",
    "        X[i] = arr[:]  # берём 166 бит (1..166)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38f54498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0]], shape=(7, 167), dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maccs_fp(smileses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad291e",
   "metadata": {},
   "source": [
    "### Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ec75e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def physchem_descriptors(smiles_list, return_names=False):\n",
    "    names = [n for n, _ in Descriptors._descList]\n",
    "    calc = MolecularDescriptorCalculator(names)\n",
    "    N, D = len(smiles_list), len(names)\n",
    "\n",
    "    # считаем в float64, чтобы не ловить overflow в цикле\n",
    "    X = np.full((N, D), np.nan, dtype=np.float64)\n",
    "\n",
    "    for i, smi in enumerate(smiles_list):\n",
    "        mol = Chem.MolFromSmiles(str(smi) if smi is not None else \"\")\n",
    "        if mol is None:\n",
    "            continue\n",
    "        try:\n",
    "            vals = np.asarray(calc.CalcDescriptors(mol), dtype=np.float64)\n",
    "            # нечисловые значения -> NaN (чтобы потом колонка отфильтровалась)\n",
    "            vals[~np.isfinite(vals)] = np.nan\n",
    "            X[i] = vals\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # маска колонок без NaN\n",
    "    keep = ~np.isnan(X).any(axis=0)\n",
    "    X = X[:, keep]\n",
    "    X = np.clip(X, -1e9, 1e9).astype(np.float32, copy=False)\n",
    "    kept_names = [n for n, k in zip(names, keep) if k]\n",
    "\n",
    "    return (X, kept_names) if return_names else X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39024fa8",
   "metadata": {},
   "source": [
    "### Pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5b608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0009727",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "mdl = AutoModel.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "@torch.no_grad()\n",
    "def chemberta_embed(smiles_list, tok, mdl,\n",
    "                    batch_size=64, max_len=128, pooling=\"mean\", device=None):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    mdl.to(device).eval()\n",
    "    out = []\n",
    "    for i in range(0, len(smiles_list), batch_size):\n",
    "        batch = [str(s) if s is not None else \"\" for s in smiles_list[i:i+batch_size]]\n",
    "        enc = tok(batch, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\").to(device)\n",
    "        h = mdl(**enc).last_hidden_state \n",
    "        if pooling == \"cls\":\n",
    "            pooled = h[:, 0]\n",
    "        else:\n",
    "            m = enc[\"attention_mask\"].unsqueeze(-1)\n",
    "            pooled = (h * m).sum(1) / m.sum(1).clamp(min=1)\n",
    "        out.append(pooled.detach().cpu().numpy())\n",
    "    return np.vstack(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a49a94b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23657979, -0.39311787, -0.49733528, ...,  0.02844087,\n",
       "        -0.16161488,  0.06855042],\n",
       "       [ 0.01253446, -0.24209289, -0.20824078, ..., -0.03621006,\n",
       "        -0.20099978,  0.1657696 ],\n",
       "       [ 0.38088298, -0.3987004 , -0.76109195, ...,  0.18910536,\n",
       "         0.00204533,  0.24978273],\n",
       "       ...,\n",
       "       [ 0.24788767, -0.43359447, -0.63609624, ...,  0.07548268,\n",
       "         0.20819755,  0.34934604],\n",
       "       [ 0.2242443 , -0.4126285 , -0.27724662, ...,  0.03192327,\n",
       "         0.17654993,  0.2161503 ],\n",
       "       [ 0.7941891 , -0.25084215,  0.42892194, ..., -0.07675749,\n",
       "         0.32636815,  0.05392162]], shape=(7, 768), dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemberta_embed(smileses, tok, mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ccdb81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32adc7d7",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b43cb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold, GroupKFold\n",
    "\n",
    "def stratified_group_splits(df, label_col=\"label\", group_cols=(\"sequence\",\"canonical_smiles\"),\n",
    "                            n_splits=5, random_state=42):\n",
    "    groups = df[list(group_cols)].astype(str).agg(\"||\".join, axis=1)\n",
    "    sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    splits = []\n",
    "    for tr, va in sgkf.split(X=np.zeros(len(df)), y=df[label_col].values, groups=groups.values):\n",
    "        splits.append((tr, va))\n",
    "    return splits\n",
    "\n",
    "def cold_aptamer_splits(df, n_splits=5, group_col=\"sequence\"):\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    groups = df[group_col].astype(str).values\n",
    "    y = df[\"label\"].values if \"label\" in df.columns else np.zeros(len(df))\n",
    "    return [(tr, va) for tr, va in gkf.split(X=np.zeros(len(df)), y=y, groups=groups)]\n",
    "\n",
    "def cold_molecule_splits(df, n_splits=5, group_col=\"canonical_smiles\"):\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    groups = df[group_col].astype(str).values\n",
    "    y = df[\"label\"].values if \"label\" in df.columns else np.zeros(len(df))\n",
    "    return [(tr, va) for tr, va in gkf.split(X=np.zeros(len(df)), y=y, groups=groups)]\n",
    "\n",
    "\n",
    "def cold_both_splits(df, n_splits=5, seq_col=\"sequence\", mol_col=\"canonical_smiles\", random_state=42):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    uniq_seqs = df[seq_col].astype(str).unique()\n",
    "    uniq_mols = df[mol_col].astype(str).unique()\n",
    "    rng.shuffle(uniq_seqs)\n",
    "    rng.shuffle(uniq_mols)\n",
    "\n",
    "    seq_fold = {s: i % n_splits for i, s in enumerate(uniq_seqs)}\n",
    "    mol_fold = {m: i % n_splits for i, m in enumerate(uniq_mols)}\n",
    "\n",
    "    s_f = df[seq_col].astype(str).map(seq_fold).to_numpy()\n",
    "    m_f = df[mol_col].astype(str).map(mol_fold).to_numpy()\n",
    "\n",
    "    splits = []\n",
    "    for f in range(n_splits):\n",
    "        val_mask = (s_f == f) | (m_f == f)\n",
    "        train_mask = (s_f != f) & (m_f != f)\n",
    "        val_idx = np.where(val_mask)[0]\n",
    "        train_idx = np.where(train_mask)[0]\n",
    "        splits.append((train_idx, val_idx))\n",
    "    return splits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed776301",
   "metadata": {},
   "source": [
    "## Compute combined embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e731f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# ========= wrappers, using YOUR feature functions =========\n",
    "\n",
    "def make_apt_features(df, cfg):\n",
    "    \"\"\"\n",
    "    cfg:\n",
    "      {'name':'kmer',   'k':6}\n",
    "      {'name':'onehot', 'max_len':216}\n",
    "      {'name':'gena',   'model_name':'AIRI-Institute/gena-lm-bert-base-t2t-multi', 'max_len':216, 'batch_size':64}\n",
    "    Возвращает np.ndarray (N, D)\n",
    "    \"\"\"\n",
    "    name = cfg.get('name')\n",
    "    seqs  = df['sequence'].tolist()\n",
    "    types = df['type'].tolist()\n",
    "\n",
    "    if name == 'kmer':\n",
    "        return kmer_freq_with_type_bit(seqs, types, k=cfg.get('k', 6)).astype(np.float64)\n",
    "    elif name == 'onehot':\n",
    "        return onehot_with_type_bit(seqs, types, max_len=cfg.get('max_len', 216)).astype(np.float64)\n",
    "    elif name == 'gena':\n",
    "        return gena_embed(\n",
    "            seqs, types,\n",
    "            model_name=cfg.get('model_name', 'AIRI-Institute/gena-lm-bert-base-t2t-multi'),\n",
    "            max_len=cfg.get('max_len', 216),\n",
    "            batch_size=cfg.get('batch_size', 64)\n",
    "        ).astype(np.float64)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown apt feature: {name}\")\n",
    "\n",
    "def make_mol_features(df, cfg):\n",
    "    \"\"\"\n",
    "    cfg:\n",
    "      {'name':'morgan','n_bits':2048,'radius':2,'counts':False}\n",
    "      {'name':'maccs'}\n",
    "      {'name':'physchem'}\n",
    "      {'name':'chemberta','tok':tok,'mdl':mdl,'batch_size':64,'max_len':128,'pooling':'mean'}\n",
    "      {'name':'concat','parts':[ ...под-конфиги как выше... ]}\n",
    "    Возвращает np.ndarray (N, D)\n",
    "    \"\"\"\n",
    "    name = cfg.get('name')\n",
    "    smiles = df['canonical_smiles'].tolist()\n",
    "\n",
    "    if name == 'morgan':\n",
    "        return morgan_fp(\n",
    "            smiles,\n",
    "            n_bits=cfg.get('n_bits', 2048),\n",
    "            radius=cfg.get('radius', 2),\n",
    "            counts=cfg.get('counts', False)\n",
    "        ).astype(np.float64)\n",
    "\n",
    "    elif name == 'maccs':\n",
    "        # твоя maccs_fp возвращает 167 бит (включая бит 0 RDKit) — используем как есть\n",
    "        return maccs_fp(smiles).astype(np.float64)\n",
    "\n",
    "    elif name == 'physchem':\n",
    "        return physchem_descriptors(smiles).astype(np.float64)\n",
    "\n",
    "    elif name == 'chemberta':\n",
    "        tok = cfg['tok']; mdl = cfg['mdl']\n",
    "        return chemberta_embed(\n",
    "            smiles, tok, mdl,\n",
    "            batch_size=cfg.get('batch_size', 64),\n",
    "            max_len=cfg.get('max_len', 128),\n",
    "            pooling=cfg.get('pooling', 'mean'),\n",
    "            device=cfg.get('device', None)\n",
    "        ).astype(np.float64)\n",
    "\n",
    "    elif name == 'concat':\n",
    "        mats = [make_mol_features(df, c) for c in cfg.get('parts', [])]\n",
    "        return np.concatenate(mats, axis=1).astype(np.float64) if mats else np.zeros((len(df), 0), dtype=np.float64)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mol feature: {name}\")\n",
    "\n",
    "\n",
    "def _get_splits(df, split_mode=\"group\", n_splits=5, random_state=42):\n",
    "    if split_mode == \"group\":\n",
    "        return stratified_group_splits(df, n_splits=n_splits, random_state=random_state)\n",
    "    elif split_mode == \"cold_aptamer\":\n",
    "        return cold_aptamer_splits(df, n_splits=n_splits)\n",
    "    elif split_mode == \"cold_molecule\":\n",
    "        return cold_molecule_splits(df, n_splits=n_splits)\n",
    "    elif split_mode == \"cold_both\":\n",
    "        return cold_both_splits(df, n_splits=n_splits, random_state=random_state)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown split_mode: {split_mode}\")\n",
    "\n",
    "# ========= models & utils =========\n",
    "\n",
    "def _model_factory(name, random_state=42):\n",
    "    name = name.lower()\n",
    "    if name in (\"logreg\",\"logistic\",\"logistic_regression\"):\n",
    "        return LogisticRegression(max_iter=2000, class_weight=\"balanced\", n_jobs=-1, solver=\"lbfgs\")\n",
    "    if name in (\"rf\",\"randomforest\",\"random_forest\"):\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=500, max_depth=None, n_jobs=-1, class_weight=\"balanced_subsample\", random_state=random_state\n",
    "        )\n",
    "    if name in (\"mlp\",):\n",
    "        return MLPClassifier(hidden_layer_sizes=(256,128), activation=\"relu\",\n",
    "                             learning_rate_init=1e-3, alpha=1e-4,\n",
    "                             max_iter=120, early_stopping=True, random_state=random_state)\n",
    "    if name in (\"lgbm\",\"lightgbm\"):\n",
    "        try:\n",
    "            from lightgbm import LGBMClassifier\n",
    "        except Exception:\n",
    "            return None\n",
    "        return LGBMClassifier(\n",
    "            n_estimators=600, learning_rate=0.05, max_depth=-1,\n",
    "            subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,\n",
    "            random_state=random_state, n_jobs=-1, verbosity=-1\n",
    "        )\n",
    "    raise ValueError(f\"Unknown model: {name}\")\n",
    "\n",
    "def _cfg_name(cfg, side):\n",
    "    n = cfg.get(\"name\",\"?\")\n",
    "    if side==\"apt\":\n",
    "        if n==\"kmer\":   return f\"kmer(k={cfg.get('k',6)})\"\n",
    "        if n==\"onehot\": return f\"onehot(L={cfg.get('max_len',216)})\"\n",
    "        if n==\"gena\":   return f\"gena(mean,last)\"\n",
    "    else:\n",
    "        if n==\"morgan\":    return f\"morgan({cfg.get('n_bits',2048)},{cfg.get('radius',2)}{'c' if cfg.get('counts',False) else 'b'})\"\n",
    "        if n==\"maccs\":     return \"maccs(167)\"\n",
    "        if n==\"physchem\":  return \"physchem(full)\"\n",
    "        if n==\"chemberta\": return \"chemberta(mean)\"\n",
    "        if n==\"concat\":    return \"concat(\" + \"+\".join(_cfg_name(c,'mol') for c in cfg.get('parts',[])) + \")\"\n",
    "    return n\n",
    "\n",
    "def _best_f1(y_true, y_score):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    thr = np.linspace(0,1,201)\n",
    "    best = 0.0\n",
    "    for t in thr:\n",
    "        p = (y_score >= t).astype(int)\n",
    "        best = max(best, f1_score(y_true, p, zero_division=0))\n",
    "    return best\n",
    "\n",
    "# ========= main: screening =========\n",
    "\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, f1_score, matthews_corrcoef\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "def screen_models(\n",
    "    df,\n",
    "    apt_cfgs,\n",
    "    mol_cfgs,\n",
    "    model_names=(\"logreg\",\"rf\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"group\",\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    scale=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Возвращает dict {model_name: DataFrame}, где строки — apt-конфиги, колонки — mol-конфиги,\n",
    "    значение — строка \"PR mean±std | ROC mean±std | F1 mean±std | MCC mean±std\".\n",
    "\n",
    "    ВАЖНО: F1 и MCC считаются по бинарным предсказаниям clf.predict(X) (дефолтный порог модели).\n",
    "    \"\"\"\n",
    "    df = df.reset_index(drop=True)\n",
    "    y = df[\"label\"].to_numpy().astype(int)\n",
    "    splits = _get_splits(df, split_mode=split_mode, n_splits=n_splits, random_state=random_state)\n",
    "\n",
    "    # предрасчёт фич\n",
    "    apt_map = {}\n",
    "    for a in apt_cfgs:\n",
    "        an = _cfg_name(a, 'apt')\n",
    "        apt_map[an] = make_apt_features(df, a)\n",
    "\n",
    "    mol_map = {}\n",
    "    for m in mol_cfgs:\n",
    "        mn = _cfg_name(m, 'mol')\n",
    "        mol_map[mn] = make_mol_features(df, m)\n",
    "\n",
    "    # таблицы\n",
    "    rows = [ _cfg_name(a,'apt') for a in apt_cfgs ]\n",
    "    cols = [ _cfg_name(m,'mol') for m in mol_cfgs ]\n",
    "    results = {}\n",
    "\n",
    "    for model_name in tqdm(model_names):\n",
    "        clf_proto = _model_factory(model_name, random_state=random_state)\n",
    "        if clf_proto is None:\n",
    "            results[model_name] = pd.DataFrame(\"N/A\", index=rows, columns=cols)\n",
    "            continue\n",
    "\n",
    "        table = pd.DataFrame(index=rows, columns=cols, dtype=object)\n",
    "\n",
    "        for ar in tqdm(rows):\n",
    "            Xa = apt_map[ar].astype(np.float64)\n",
    "            for mc in tqdm(cols):\n",
    "                Xm = mol_map[mc].astype(np.float64)\n",
    "                X = np.concatenate([Xa, Xm], axis=1)\n",
    "\n",
    "                pr_list, roc_list, f1_list, mcc_list, npr_list = [], [], [], [], []\n",
    "                for tr, va in splits:\n",
    "                    Xtr, Xva = X[tr], X[va]\n",
    "                    ytr, yva = y[tr], y[va]\n",
    "\n",
    "                    if scale:\n",
    "                        scaler = StandardScaler()\n",
    "                        Xtr = scaler.fit_transform(Xtr)\n",
    "                        Xva = scaler.transform(Xva)\n",
    "\n",
    "                    clf = _model_factory(model_name, random_state=random_state)\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names.*\")\n",
    "                        clf.fit(Xtr, ytr)\n",
    "\n",
    "                    # непрерывный счёт для PR/ROC\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names.*\")\n",
    "                        if hasattr(clf, \"predict_proba\"):\n",
    "                            s = clf.predict_proba(Xva)[:, 1]\n",
    "                        elif hasattr(clf, \"decision_function\"):\n",
    "                            d = clf.decision_function(Xva)\n",
    "                            s = (d - d.min()) / (d.max() - d.min() + 1e-8)\n",
    "                        else:\n",
    "                            s = clf.predict(Xva).astype(float)  # деградация, если нет score\n",
    "\n",
    "                    # бинарные предсказания по дефолтному порогу модели\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names.*\")\n",
    "                        yhat = clf.predict(Xva)\n",
    "\n",
    "                    pr  = average_precision_score(yva, s) if len(np.unique(yva))>1 else np.nan\n",
    "                    p = yva.mean()\n",
    "                    npr = (pr - p) / (1 - p + 1e-12)\n",
    "                    \n",
    "                    roc = roc_auc_score(yva, s) if len(np.unique(yva))>1 else np.nan\n",
    "                    f1  = f1_score(yva, yhat, zero_division=0)\n",
    "                    mcc = matthews_corrcoef(yva, yhat)\n",
    "\n",
    "                    pr_list.append(pr); roc_list.append(roc); f1_list.append(f1); mcc_list.append(mcc), npr_list.append(npr)\n",
    "\n",
    "                def fmt(arr):\n",
    "                    arr = np.array(arr, dtype=float)\n",
    "                    return f\"{np.nanmean(arr):.3f}±{np.nanstd(arr):.3f}\"\n",
    "\n",
    "                table.loc[ar, mc] = (\n",
    "                    f\"PR {fmt(pr_list)} | ROC {fmt(roc_list)} | F1 {fmt(f1_list)} | MCC {fmt(mcc_list)}| nPR {fmt(npr_list)}\"\n",
    "                )\n",
    "\n",
    "        results[model_name] = table\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f7d569",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef66a9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apt_cfgs: 5 вариантов\n"
     ]
    }
   ],
   "source": [
    "apt_cfgs = []\n",
    "\n",
    "# k-mer\n",
    "for k in [3, 4, 5]:\n",
    "    apt_cfgs.append({'name': 'kmer', 'k': k})\n",
    "\n",
    "# one-hot\n",
    "for L in [216]:\n",
    "    apt_cfgs.append({'name': 'onehot', 'max_len': L})\n",
    "\n",
    "# GENA-LM (подставляет модель прямо в функции по имени)\n",
    "gena_models = [\n",
    "    'AIRI-Institute/gena-lm-bert-base-t2t-multi']\n",
    "for model_name, max_len, batch_size in product(gena_models, [216], [64]):\n",
    "    apt_cfgs.append({'name': 'gena', 'model_name': model_name, 'max_len': max_len, 'batch_size': batch_size})\n",
    "\n",
    "print(f\"apt_cfgs: {len(apt_cfgs)} вариантов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfdd32d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mol_cfgs: 3 вариантов\n"
     ]
    }
   ],
   "source": [
    "mol_cfgs = []\n",
    "\n",
    "# Morgan (все комбинации сетки)\n",
    "for n_bits, radius, counts in product([1024], [2], [True]):\n",
    "    mol_cfgs.append({'name': 'morgan', 'n_bits': n_bits, 'radius': radius, 'counts': counts})\n",
    "\n",
    "# MACCS\n",
    "mol_cfgs.append({'name': 'maccs'})\n",
    "\n",
    "# Полные physchem дескрипторы (с последующей фильтрацией NaN-колонок в твоей функции)\n",
    "#mol_cfgs.append({'name': 'physchem'})\n",
    "\n",
    "# ChemBERTa (использует уже созданные тобой tok/mdl)\n",
    "mol_cfgs.append({'name': 'chemberta', 'tok': tok, 'mdl': mdl,\n",
    "                'batch_size': 64, 'max_len': max_len, 'pooling': 'mean'})\n",
    "\n",
    "\n",
    "\n",
    "print(f\"mol_cfgs: {len(mol_cfgs)} вариантов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eeeb09",
   "metadata": {},
   "source": [
    "## No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efba8787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py:1773: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [01:13<00:00, 10.51s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [00:49<00:00,  7.05s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [00:57<00:00,  8.24s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [00:55<00:00,  7.92s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [00:47<00:00,  6.81s/it]\n",
      "100%|██████████| 5/5 [04:43<00:00, 56.75s/it]\n",
      " 25%|██▌       | 1/4 [04:43<14:11, 283.77s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [00:39<00:00,  5.67s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [00:40<00:00,  5.77s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [00:44<00:00,  6.38s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [00:41<00:00,  5.99s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [00:57<00:00,  8.27s/it]\n",
      "100%|██████████| 5/5 [03:44<00:00, 44.93s/it]\n",
      " 50%|█████     | 2/4 [08:28<08:17, 248.98s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [00:55<00:00,  7.99s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [01:05<00:00,  9.36s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [01:23<00:00, 11.91s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [00:50<00:00,  7.23s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [03:49<00:00, 32.79s/it]\n",
      "100%|██████████| 5/5 [08:05<00:00, 97.01s/it] \n",
      " 75%|███████▌  | 3/4 [16:33<05:56, 356.83s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [01:06<00:00,  9.52s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [00:51<00:00,  7.31s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [01:28<00:00, 12.63s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [01:28<00:00, 12.60s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 7/7 [01:18<00:00, 11.23s/it]\n",
      "100%|██████████| 5/5 [06:13<00:00, 74.62s/it]\n",
      "100%|██████████| 4/4 [22:46<00:00, 341.67s/it]\n"
     ]
    }
   ],
   "source": [
    "res_1_0_group = screen_models(\n",
    "    df,\n",
    "    apt_cfgs=apt_cfgs,\n",
    "    mol_cfgs=mol_cfgs,\n",
    "    model_names=(\"logreg\",\"rf\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"group\",\n",
    "    n_splits=5,\n",
    "    scale=True,   # включи True, если в признаках много непрерывных чисел (emb/physchem)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c8e9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1_0_group['mlp'].to_excel('res_no_aug_mlp.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91a26dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py:1773: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:55<00:00, 13.99s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:25<00:00,  6.27s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:27<00:00,  6.96s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:28<00:00,  7.20s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:27<00:00,  6.83s/it]\n",
      "100%|██████████| 5/5 [02:45<00:00, 33.02s/it]\n",
      " 25%|██▌       | 1/4 [02:45<08:15, 165.09s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:23<00:00,  5.79s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:23<00:00,  5.96s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:25<00:00,  6.27s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:23<00:00,  5.90s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:34<00:00,  8.61s/it]\n",
      "100%|██████████| 5/5 [02:10<00:00, 26.03s/it]\n",
      " 50%|█████     | 2/4 [04:55<04:49, 144.54s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:40<00:00, 10.08s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:46<00:00, 11.74s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:05<00:00, 16.45s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:45<00:00, 11.42s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [02:29<00:00, 37.44s/it]\n",
      "100%|██████████| 5/5 [05:48<00:00, 69.71s/it]\n",
      " 75%|███████▌  | 3/4 [10:43<03:57, 237.69s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:24<00:00,  6.00s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:26<00:00,  6.70s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:51<00:00, 12.76s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:36<00:00,  9.07s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:43<00:00, 10.96s/it]\n",
      "100%|██████████| 5/5 [03:01<00:00, 36.39s/it]\n",
      "100%|██████████| 4/4 [13:45<00:00, 206.43s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res_1_0_cold_aptamer = screen_models(\n",
    "    df,\n",
    "    apt_cfgs=apt_cfgs,\n",
    "    mol_cfgs=mol_cfgs,\n",
    "    model_names=(\"logreg\",\"rf\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"cold_aptamer\",\n",
    "    n_splits=5,\n",
    "    scale=True,   # включи True, если в признаках много непрерывных чисел (emb/physchem)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031706f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8461829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py:1773: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:52<00:00, 13.20s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:24<00:00,  6.01s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:27<00:00,  6.80s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:27<00:00,  6.88s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:27<00:00,  6.80s/it]\n",
      "100%|██████████| 5/5 [02:38<00:00, 31.76s/it]\n",
      " 25%|██▌       | 1/4 [02:38<07:56, 158.78s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:22<00:00,  5.52s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:23<00:00,  5.80s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:25<00:00,  6.28s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:23<00:00,  5.83s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:34<00:00,  8.56s/it]\n",
      "100%|██████████| 5/5 [02:07<00:00, 25.59s/it]\n",
      " 50%|█████     | 2/4 [04:46<04:41, 140.66s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:36<00:00,  9.09s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:46<00:00, 11.61s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:02<00:00, 15.56s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:38<00:00,  9.67s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [02:04<00:00, 31.11s/it]\n",
      "100%|██████████| 5/5 [05:08<00:00, 61.64s/it]\n",
      " 75%|███████▌  | 3/4 [09:54<03:37, 217.17s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:20<00:00,  5.14s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:19<00:00,  4.83s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:42<00:00, 10.60s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:39<00:00,  9.86s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:39<00:00,  9.76s/it]\n",
      "100%|██████████| 5/5 [02:40<00:00, 32.16s/it]\n",
      "100%|██████████| 4/4 [12:35<00:00, 188.94s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res_1_0_cold_molecule = screen_models(\n",
    "    df,\n",
    "    apt_cfgs=apt_cfgs,\n",
    "    mol_cfgs=mol_cfgs,\n",
    "    model_names=(\"logreg\",\"rf\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"cold_molecule\",\n",
    "    n_splits=5,\n",
    "    scale=True,   # включи True, если в признаках много непрерывных чисел (emb/physchem)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8613e355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['logreg', 'rf', 'lgbm', 'mlp'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_1_0_cold_aptamer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a590d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py:1773: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:50<00:00, 12.69s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:23<00:00,  5.77s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:27<00:00,  6.85s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:25<00:00,  6.45s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:24<00:00,  6.19s/it]\n",
      "100%|██████████| 5/5 [02:31<00:00, 30.38s/it]\n",
      " 25%|██▌       | 1/4 [02:31<07:35, 151.90s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:19<00:00,  4.89s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:20<00:00,  5.06s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:21<00:00,  5.46s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:20<00:00,  5.06s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:28<00:00,  7.10s/it]\n",
      "100%|██████████| 5/5 [01:50<00:00, 22.07s/it]\n",
      " 50%|█████     | 2/4 [04:22<04:14, 127.47s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:31<00:00,  8.00s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:38<00:00,  9.60s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:56<00:00, 14.22s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:45<00:00, 11.32s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [02:02<00:00, 30.70s/it]\n",
      "100%|██████████| 5/5 [04:55<00:00, 59.07s/it]\n",
      " 75%|███████▌  | 3/4 [09:17<03:24, 204.13s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:18<00:00,  4.64s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:21<00:00,  5.31s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:37<00:00,  9.28s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:33<00:00,  8.44s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:33<00:00,  8.27s/it]\n",
      "100%|██████████| 5/5 [02:23<00:00, 28.77s/it]\n",
      "100%|██████████| 4/4 [11:41<00:00, 175.37s/it]\n"
     ]
    }
   ],
   "source": [
    "res_1_0_cold_both = screen_models(\n",
    "    df,\n",
    "    apt_cfgs=apt_cfgs,\n",
    "    mol_cfgs=mol_cfgs,\n",
    "    model_names=(\"logreg\",\"rf\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"cold_both\",\n",
    "    n_splits=5,\n",
    "    scale=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc0fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f429cd",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab816b8f",
   "metadata": {},
   "source": [
    "### 1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60dce3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py:1773: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [01:05<00:00, 21.80s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:40<00:00, 13.38s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [01:03<00:00, 21.05s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [01:10<00:00, 23.49s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:53<00:00, 17.69s/it]\n",
      "100%|██████████| 5/5 [04:52<00:00, 58.47s/it]\n",
      " 33%|███▎      | 1/3 [04:52<09:44, 292.33s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:47<00:00, 15.86s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:55<00:00, 18.36s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [01:18<00:00, 26.20s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:47<00:00, 15.80s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [02:30<00:00, 50.25s/it]\n",
      "100%|██████████| 5/5 [06:19<00:00, 75.89s/it]\n",
      " 67%|██████▋   | 2/3 [11:11<05:43, 343.57s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [02:37<00:00, 52.59s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [02:00<00:00, 40.04s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [03:47<00:00, 75.74s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [03:34<00:00, 71.36s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [03:34<00:00, 71.52s/it]\n",
      "100%|██████████| 5/5 [15:33<00:00, 186.77s/it]\n",
      "100%|██████████| 3/3 [26:45<00:00, 535.20s/it]\n"
     ]
    }
   ],
   "source": [
    "res_1_3_group = screen_models(\n",
    "    augment_negatives_per_sequence(df, n_neg_per_seq=4, seed=42),\n",
    "    apt_cfgs=apt_cfgs,\n",
    "    mol_cfgs=mol_cfgs,\n",
    "    model_names=(\"logreg\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"group\",\n",
    "    n_splits=5,\n",
    "    scale=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52073a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg':                                                    morgan(1024,2c)  \\\n",
       " kmer(k=3)        PR 0.504±0.019 | ROC 0.736±0.006 | F1 0.531±0....   \n",
       " kmer(k=4)        PR 0.494±0.018 | ROC 0.743±0.010 | F1 0.538±0....   \n",
       " kmer(k=5)        PR 0.393±0.023 | ROC 0.680±0.016 | F1 0.471±0....   \n",
       " onehot(L=216)    PR 0.446±0.015 | ROC 0.703±0.012 | F1 0.510±0....   \n",
       " gena(mean,last)  PR 0.428±0.014 | ROC 0.710±0.011 | F1 0.508±0....   \n",
       " \n",
       "                                                         maccs(167)  \\\n",
       " kmer(k=3)        PR 0.409±0.016 | ROC 0.701±0.017 | F1 0.474±0....   \n",
       " kmer(k=4)        PR 0.399±0.026 | ROC 0.699±0.017 | F1 0.477±0....   \n",
       " kmer(k=5)        PR 0.303±0.020 | ROC 0.572±0.019 | F1 0.364±0....   \n",
       " onehot(L=216)    PR 0.366±0.015 | ROC 0.655±0.015 | F1 0.451±0....   \n",
       " gena(mean,last)  PR 0.335±0.012 | ROC 0.627±0.016 | F1 0.412±0....   \n",
       " \n",
       "                                                    chemberta(mean)  \n",
       " kmer(k=3)        PR 0.514±0.017 | ROC 0.749±0.005 | F1 0.544±0....  \n",
       " kmer(k=4)        PR 0.505±0.020 | ROC 0.759±0.008 | F1 0.549±0....  \n",
       " kmer(k=5)        PR 0.400±0.024 | ROC 0.684±0.016 | F1 0.476±0....  \n",
       " onehot(L=216)    PR 0.459±0.015 | ROC 0.719±0.011 | F1 0.524±0....  \n",
       " gena(mean,last)  PR 0.439±0.016 | ROC 0.724±0.010 | F1 0.516±0....  ,\n",
       " 'lgbm':                                                    morgan(1024,2c)  \\\n",
       " kmer(k=3)        PR 0.817±0.019 | ROC 0.896±0.010 | F1 0.723±0....   \n",
       " kmer(k=4)        PR 0.810±0.020 | ROC 0.889±0.011 | F1 0.709±0....   \n",
       " kmer(k=5)        PR 0.790±0.018 | ROC 0.874±0.015 | F1 0.706±0....   \n",
       " onehot(L=216)    PR 0.783±0.018 | ROC 0.873±0.013 | F1 0.687±0....   \n",
       " gena(mean,last)  PR 0.734±0.012 | ROC 0.838±0.013 | F1 0.643±0....   \n",
       " \n",
       "                                                         maccs(167)  \\\n",
       " kmer(k=3)        PR 0.783±0.011 | ROC 0.877±0.012 | F1 0.681±0....   \n",
       " kmer(k=4)        PR 0.773±0.015 | ROC 0.868±0.012 | F1 0.673±0....   \n",
       " kmer(k=5)        PR 0.753±0.013 | ROC 0.855±0.014 | F1 0.662±0....   \n",
       " onehot(L=216)    PR 0.769±0.013 | ROC 0.864±0.011 | F1 0.669±0....   \n",
       " gena(mean,last)  PR 0.657±0.014 | ROC 0.788±0.017 | F1 0.560±0....   \n",
       " \n",
       "                                                    chemberta(mean)  \n",
       " kmer(k=3)        PR 0.845±0.014 | ROC 0.908±0.012 | F1 0.748±0....  \n",
       " kmer(k=4)        PR 0.838±0.012 | ROC 0.904±0.012 | F1 0.737±0....  \n",
       " kmer(k=5)        PR 0.820±0.010 | ROC 0.892±0.011 | F1 0.717±0....  \n",
       " onehot(L=216)    PR 0.805±0.011 | ROC 0.881±0.009 | F1 0.704±0....  \n",
       " gena(mean,last)  PR 0.790±0.011 | ROC 0.877±0.011 | F1 0.676±0....  ,\n",
       " 'mlp':                                                    morgan(1024,2c)  \\\n",
       " kmer(k=3)        PR 0.782±0.023 | ROC 0.867±0.009 | F1 0.712±0....   \n",
       " kmer(k=4)        PR 0.772±0.034 | ROC 0.865±0.015 | F1 0.704±0....   \n",
       " kmer(k=5)        PR 0.737±0.023 | ROC 0.843±0.011 | F1 0.654±0....   \n",
       " onehot(L=216)    PR 0.708±0.015 | ROC 0.833±0.011 | F1 0.647±0....   \n",
       " gena(mean,last)  PR 0.726±0.030 | ROC 0.849±0.004 | F1 0.660±0....   \n",
       " \n",
       "                                                         maccs(167)  \\\n",
       " kmer(k=3)        PR 0.759±0.021 | ROC 0.874±0.011 | F1 0.694±0....   \n",
       " kmer(k=4)        PR 0.721±0.030 | ROC 0.847±0.016 | F1 0.649±0....   \n",
       " kmer(k=5)        PR 0.673±0.016 | ROC 0.805±0.020 | F1 0.604±0....   \n",
       " onehot(L=216)    PR 0.673±0.040 | ROC 0.798±0.021 | F1 0.602±0....   \n",
       " gena(mean,last)  PR 0.662±0.028 | ROC 0.810±0.018 | F1 0.588±0....   \n",
       " \n",
       "                                                    chemberta(mean)  \n",
       " kmer(k=3)        PR 0.769±0.016 | ROC 0.875±0.016 | F1 0.702±0....  \n",
       " kmer(k=4)        PR 0.752±0.020 | ROC 0.874±0.013 | F1 0.679±0....  \n",
       " kmer(k=5)        PR 0.742±0.023 | ROC 0.861±0.006 | F1 0.668±0....  \n",
       " onehot(L=216)    PR 0.728±0.019 | ROC 0.848±0.014 | F1 0.667±0....  \n",
       " gena(mean,last)  PR 0.748±0.010 | ROC 0.861±0.016 | F1 0.662±0....  }"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_1_3_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd354994",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in res_1_3_group.keys():\n",
    "    res_1_3_group[model].to_excel(f'res_1_4_aug_{model}_group.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b540f",
   "metadata": {},
   "source": [
    "### 1 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b24c7127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py:1773: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:06<00:00, 16.56s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:36<00:00,  9.21s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:55<00:00, 13.96s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:04<00:00, 16.14s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:49<00:00, 12.33s/it]\n",
      "100%|██████████| 5/5 [04:33<00:00, 54.60s/it]\n",
      " 25%|██▌       | 1/4 [04:33<13:39, 273.03s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:39<00:00,  9.97s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:41<00:00, 10.49s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:49<00:00, 12.48s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:41<00:00, 10.41s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:39<00:00, 24.86s/it]\n",
      "100%|██████████| 5/5 [04:32<00:00, 54.58s/it]\n",
      " 50%|█████     | 2/4 [09:05<09:05, 272.96s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:03<00:00, 15.90s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:11<00:00, 17.78s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:36<00:00, 24.09s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:59<00:00, 14.87s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [03:26<00:00, 51.66s/it]\n",
      "100%|██████████| 5/5 [08:17<00:00, 99.45s/it] \n",
      " 75%|███████▌  | 3/4 [17:23<06:15, 375.38s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:53<00:00, 28.39s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:35<00:00, 23.92s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [03:34<00:00, 53.51s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [02:41<00:00, 40.31s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [02:30<00:00, 37.71s/it]\n",
      "100%|██████████| 5/5 [12:15<00:00, 147.07s/it]\n",
      "100%|██████████| 4/4 [29:38<00:00, 444.64s/it]\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py:1773: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:09<00:00, 17.41s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:35<00:00,  8.85s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:48<00:00, 12.21s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:54<00:00, 13.57s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:47<00:00, 11.89s/it]\n",
      "100%|██████████| 5/5 [04:15<00:00, 51.15s/it]\n",
      " 25%|██▌       | 1/4 [04:15<12:47, 255.77s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:35<00:00,  8.75s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:36<00:00,  9.14s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:44<00:00, 11.17s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:36<00:00,  9.11s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:30<00:00, 22.59s/it]\n",
      "100%|██████████| 5/5 [04:03<00:00, 48.62s/it]\n",
      " 50%|█████     | 2/4 [08:18<08:16, 248.31s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:58<00:00, 14.67s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:02<00:00, 15.69s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:31<00:00, 22.97s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:57<00:00, 14.38s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [02:46<00:00, 41.59s/it]\n",
      "100%|██████████| 5/5 [07:17<00:00, 87.45s/it] \n",
      " 75%|███████▌  | 3/4 [15:36<05:34, 334.59s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:45<00:00, 26.39s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:40<00:00, 25.06s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [03:14<00:00, 48.65s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [02:29<00:00, 37.48s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [02:17<00:00, 34.41s/it]\n",
      "100%|██████████| 5/5 [11:28<00:00, 137.61s/it]\n",
      "100%|██████████| 4/4 [27:04<00:00, 406.05s/it]\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py:1773: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:59<00:00, 14.77s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:36<00:00,  9.24s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:53<00:00, 13.43s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:58<00:00, 14.62s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:45<00:00, 11.45s/it]\n",
      "100%|██████████| 5/5 [04:14<00:00, 50.82s/it]\n",
      " 25%|██▌       | 1/4 [04:14<12:42, 254.10s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:34<00:00,  8.65s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:37<00:00,  9.33s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:46<00:00, 11.61s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:38<00:00,  9.51s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:37<00:00, 24.49s/it]\n",
      "100%|██████████| 5/5 [04:14<00:00, 50.88s/it]\n",
      " 50%|█████     | 2/4 [08:28<08:28, 254.29s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:00<00:00, 15.02s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:05<00:00, 16.46s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:29<00:00, 22.30s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:47<00:00, 11.90s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [02:47<00:00, 41.75s/it]\n",
      "100%|██████████| 5/5 [07:09<00:00, 85.96s/it] \n",
      " 75%|███████▌  | 3/4 [15:38<05:34, 334.44s/it]\n",
      "\u001b[Ac:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:788: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:22<00:00, 20.62s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [01:43<00:00, 25.88s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [04:01<00:00, 60.48s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[Ac:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:788: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:788: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:788: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:788: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "\n",
      "100%|██████████| 4/4 [03:00<00:00, 45.02s/it]\n",
      "\n",
      "\u001b[Ac:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:788: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:788: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:788: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "\n",
      "\u001b[Ac:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:788: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "res_1_2_group = screen_models(\n",
    "    df=augment_negatives_per_sequence(df, n_neg_per_seq=2, seed=42),\n",
    "    apt_cfgs=apt_cfgs,\n",
    "    mol_cfgs=mol_cfgs,\n",
    "    model_names=(\"logreg\",\"rf\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"group\",\n",
    "    n_splits=5,\n",
    "    scale=True,   # включи True, если в признаках много непрерывных чисел (emb/physchem)\n",
    ")\n",
    "\n",
    "res_1_2_cold_aptamer = screen_models(\n",
    "    df=augment_negatives_per_sequence(df, n_neg_per_seq=2, seed=42),\n",
    "    apt_cfgs=apt_cfgs,\n",
    "    mol_cfgs=mol_cfgs,\n",
    "    model_names=(\"logreg\",\"rf\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"cold_aptamer\",\n",
    "    n_splits=5,\n",
    "    scale=True,   # включи True, если в признаках много непрерывных чисел (emb/physchem)\n",
    ")\n",
    "\n",
    "res_1_2_cold_molecule = screen_models(\n",
    "    df=augment_negatives_per_sequence(df, n_neg_per_seq=2, seed=42),\n",
    "    apt_cfgs=apt_cfgs,\n",
    "    mol_cfgs=mol_cfgs,\n",
    "    model_names=(\"logreg\",\"rf\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"cold_molecule\",\n",
    "    n_splits=5,\n",
    "    scale=True,   # включи True, если в признаках много непрерывных чисел (emb/physchem)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63921a38",
   "metadata": {},
   "source": [
    "### 1 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4678ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1_3_group = screen_models(\n",
    "    df=augment_negatives_per_sequence(df, n_neg_per_seq=3, seed=42),\n",
    "    apt_cfgs=apt_cfgs,\n",
    "    mol_cfgs=mol_cfgs,\n",
    "    model_names=(\"logreg\",\"rf\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"group\",\n",
    "    n_splits=5,\n",
    "    scale=False,   # включи True, если в признаках много непрерывных чисел (emb/physchem)\n",
    ")\n",
    "\n",
    "res_1_3_cold_aptamer = screen_models(\n",
    "    df=augment_negatives_per_sequence(df, n_neg_per_seq=3, seed=42),\n",
    "    apt_cfgs=apt_cfgs,\n",
    "    mol_cfgs=mol_cfgs,\n",
    "    model_names=(\"logreg\",\"rf\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"cold_aptamer\",\n",
    "    n_splits=5,\n",
    "    scale=False,   # включи True, если в признаках много непрерывных чисел (emb/physchem)\n",
    ")\n",
    "\n",
    "res_1_3_cold_molecule = screen_models(\n",
    "    df=augment_negatives_per_sequence(df, n_neg_per_seq=3, seed=42),\n",
    "    apt_cfgs=apt_cfgs,\n",
    "    mol_cfgs=mol_cfgs,\n",
    "    model_names=(\"logreg\",\"rf\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"cold_molecule\",\n",
    "    n_splits=5,\n",
    "    scale=False,   # включи True, если в признаках много непрерывных чисел (emb/physchem)\n",
    ")\n",
    "\n",
    "res_1_3_cold_both = screen_models(\n",
    "    df=augment_negatives_per_sequence(df, n_neg_per_seq=3, seed=42),\n",
    "    apt_cfgs=apt_cfgs,\n",
    "    mol_cfgs=mol_cfgs,\n",
    "    model_names=(\"logreg\",\"rf\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"cold_both\",\n",
    "    n_splits=5,\n",
    "    scale=False,   # включи True, если в признаках много непрерывных чисел (emb/physchem)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fa85a8",
   "metadata": {},
   "source": [
    "### 1 to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dabc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29fe6354",
   "metadata": {},
   "source": [
    "### Ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c259912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# --- 1) генерация случайных фич той же размерности ---\n",
    "def randomize_like(X, how=\"permute\", seed=42):\n",
    "    \"\"\"\n",
    "    X: np.ndarray (N, D)\n",
    "    how=\"permute\"  — перетасовать значения в каждом столбце (сохр. маргинали и масштаб).\n",
    "    how=\"gaussian\" — сэмплировать N(mean_j, std_j) для каждого столбца.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = np.asarray(X)\n",
    "    N, D = X.shape\n",
    "    R = np.empty_like(X, dtype=float)\n",
    "\n",
    "    if how == \"permute\":\n",
    "        R[:] = X\n",
    "        for j in range(D):\n",
    "            rng.shuffle(R[:, j])       # тасуем значения этого признака по объектам\n",
    "        return R\n",
    "\n",
    "    elif how == \"gaussian\":\n",
    "        mu = np.nanmean(X, axis=0)\n",
    "        sd = np.nanstd(X, axis=0)\n",
    "        sd = np.where(sd == 0, 1.0, sd)\n",
    "        return rng.normal(loc=mu, scale=sd, size=(N, D))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"how must be 'permute' or 'gaussian'\")\n",
    "\n",
    "# --- 2) контекстная подмена фабрик фич ---\n",
    "@contextmanager\n",
    "def random_feature_ablation(side=\"both\", how=\"permute\", seed=42):\n",
    "    \"\"\"\n",
    "    side: 'apt' | 'mol' | 'both'\n",
    "    Подменяет make_apt_features/make_mol_features так, чтобы они\n",
    "    возвращали случайные фичи той же размерности.\n",
    "    \"\"\"\n",
    "    global make_apt_features, make_mol_features\n",
    "    _orig_apt = make_apt_features\n",
    "    _orig_mol = make_mol_features\n",
    "\n",
    "    def _wrap(fn):\n",
    "        def _inner(df, cfg, _fn=fn):\n",
    "            X = _fn(df, cfg)\n",
    "            return randomize_like(X, how=how, seed=seed)\n",
    "        return _inner\n",
    "\n",
    "    try:\n",
    "        if side in (\"apt\", \"both\"):\n",
    "            make_apt_features = _wrap(_orig_apt)\n",
    "        if side in (\"mol\", \"both\"):\n",
    "            make_mol_features = _wrap(_orig_mol)\n",
    "        yield\n",
    "    finally:\n",
    "        make_apt_features = _orig_apt\n",
    "        make_mol_features = _orig_mol\n",
    "\n",
    "# --- 3) сахар: вызвать твою screen_models с абляцией фич ---\n",
    "def screen_models_ablate_features(\n",
    "    df,\n",
    "    apt_cfgs,\n",
    "    mol_cfgs,\n",
    "    model_names=(\"logreg\",\"rf\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"group\",\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    scale=True,\n",
    "    side=\"both\",\n",
    "    how=\"permute\",\n",
    "    seed=42,\n",
    "):\n",
    "    with random_feature_ablation(side=side, how=how, seed=seed):\n",
    "        return screen_models(\n",
    "            df=df,\n",
    "            apt_cfgs=apt_cfgs,\n",
    "            mol_cfgs=mol_cfgs,\n",
    "            model_names=model_names,\n",
    "            split_mode=split_mode,\n",
    "            n_splits=n_splits,\n",
    "            random_state=random_state,\n",
    "            scale=scale,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64c477cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py:1773: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:26<00:00,  8.73s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:31<00:00, 10.54s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:41<00:00, 13.67s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:27<00:00,  9.10s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [01:21<00:00, 27.09s/it]\n",
      "100%|██████████| 5/5 [03:27<00:00, 41.49s/it]\n",
      " 33%|███▎      | 1/3 [03:27<06:54, 207.45s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:43<00:00, 14.45s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:16<00:00,  5.43s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:17<00:00,  5.69s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:17<00:00,  5.70s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:16<00:00,  5.62s/it]\n",
      "100%|██████████| 5/5 [01:50<00:00, 22.15s/it]\n",
      " 67%|██████▋   | 2/3 [05:18<02:30, 150.56s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:15<00:00,  5.23s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:17<00:00,  5.96s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:31<00:00, 10.48s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:28<00:00,  9.53s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:25<00:00,  8.59s/it]\n",
      "100%|██████████| 5/5 [01:59<00:00, 23.88s/it]\n",
      "100%|██████████| 3/3 [07:17<00:00, 145.86s/it]\n"
     ]
    }
   ],
   "source": [
    "res_rand = screen_models_ablate_features(df, apt_cfgs, mol_cfgs,\n",
    "                                         model_names=(\"lgbm\",\"logreg\", \"mlp\"),\n",
    "                                         split_mode=\"group\",\n",
    "                                         side=\"both\", how=\"permute\", seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06a27fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in res_rand.keys():\n",
    "    res_rand[model].to_excel(f'res_{model}_rand_ablation_both.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "556bff99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py:1773: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:48<00:00, 16.28s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [01:01<00:00, 20.44s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [01:19<00:00, 26.42s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:57<00:00, 19.25s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [01:42<00:00, 34.30s/it]\n",
      "100%|██████████| 5/5 [05:50<00:00, 70.02s/it]\n",
      " 33%|███▎      | 1/3 [05:50<11:40, 350.10s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:42<00:00, 14.20s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:16<00:00,  5.47s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:17<00:00,  5.88s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:17<00:00,  5.96s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:17<00:00,  5.91s/it]\n",
      "100%|██████████| 5/5 [01:52<00:00, 22.46s/it]\n",
      " 67%|██████▋   | 2/3 [07:42<03:30, 210.22s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:14<00:00,  4.90s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:18<00:00,  6.12s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:27<00:00,  9.29s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:27<00:00,  9.05s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:25<00:00,  8.46s/it]\n",
      "100%|██████████| 5/5 [01:53<00:00, 22.69s/it]\n",
      "100%|██████████| 3/3 [09:35<00:00, 191.96s/it]\n"
     ]
    }
   ],
   "source": [
    "res_mol_rand = screen_models_ablate_features(df, apt_cfgs, mol_cfgs,\n",
    "                                             model_names=(\"lgbm\",\"logreg\", \"mlp\"),\n",
    "                                             split_mode=\"group\",\n",
    "                                             side=\"mol\", how=\"gaussian\", seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b5be641",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in res_mol_rand.keys():\n",
    "    res_mol_rand[model].to_excel(f'res_mol_{model}_rand_ablation_both.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bb82162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "c:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py:1773: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:31<00:00, 10.60s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:47<00:00, 15.93s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [01:38<00:00, 32.74s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [01:25<00:00, 28.56s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [01:18<00:00, 26.30s/it]\n",
      "100%|██████████| 5/5 [05:42<00:00, 68.49s/it]\n",
      " 33%|███▎      | 1/3 [05:42<11:24, 342.44s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:44<00:00, 14.69s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:18<00:00,  6.15s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:17<00:00,  5.93s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:17<00:00,  5.88s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:17<00:00,  5.91s/it]\n",
      "100%|██████████| 5/5 [01:55<00:00, 23.14s/it]\n",
      " 67%|██████▋   | 2/3 [07:38<03:29, 209.08s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:20<00:00,  6.79s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:22<00:00,  7.61s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:38<00:00, 12.82s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:31<00:00, 10.33s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:29<00:00,  9.97s/it]\n",
      "100%|██████████| 5/5 [02:22<00:00, 28.52s/it]\n",
      "100%|██████████| 3/3 [10:00<00:00, 200.26s/it]\n"
     ]
    }
   ],
   "source": [
    "res_apt_rand = screen_models_ablate_features(df, apt_cfgs, mol_cfgs,\n",
    "                                             model_names=(\"lgbm\",\"logreg\", \"mlp\"),\n",
    "                                             split_mode=\"group\",\n",
    "                                             side=\"apt\", how=\"gaussian\", seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d486167",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in res_apt_rand.keys():\n",
    "    res_apt_rand[model].to_excel(f'res_apt_{model}_rand_ablation_both.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309367e0",
   "metadata": {},
   "source": [
    "### concats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "558cbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, f1_score, matthews_corrcoef\n",
    "\n",
    "# ---- НОВОЕ: компактный хелпер для смешения двух векторов признаков ----\n",
    "def fuse_features(Xa, Xm, fusion=\"concat\", proj_dim=256, random_state=42):\n",
    "    \"\"\"\n",
    "    Xa: (N, Da), Xm: (N, Dm)\n",
    "    fusion ∈ {\n",
    "        \"concat\",                # [Xa, Xm]\n",
    "        \"sum\",                   # P(Xa) + P(Xm)\n",
    "        \"hadamard\",              # P(Xa) ⊙ P(Xm)\n",
    "        \"absdiff\",               # |P(Xa) - P(Xm)|\n",
    "        \"biaffine\",              # (Xa@U) ⊙ (Xm@V)  -> k dims\n",
    "        \"poly2\"                  # [P(Xa), P(Xm), P(Xa)⊙P(Xm), |P(Xa)-P(Xm)|, P(Xa)+P(Xm)]\n",
    "    }\n",
    "    P(·) — общая линейная проекция до размера k=proj_dim, если Da!=Dm (или просто для стабилизации).\n",
    "    \"\"\"\n",
    "    Xa = np.asarray(Xa, dtype=np.float64)\n",
    "    Xm = np.asarray(Xm, dtype=np.float64)\n",
    "    Na, Da = Xa.shape\n",
    "    Nm, Dm = Xm.shape\n",
    "    assert Na == Nm, \"Xa и Xm должны иметь одинаковое число строк (N).\"\n",
    "\n",
    "    if fusion == \"concat\":\n",
    "        return np.concatenate([Xa, Xm], axis=1)\n",
    "\n",
    "    # подготовим проекции (детерминированно от размеров и random_state)\n",
    "    def proj(X, D_in, tag):\n",
    "        k = proj_dim if proj_dim is not None else min(Da, Dm)\n",
    "        # детерминированное семя под конкретную проекцию\n",
    "        seed = (hash((tag, D_in, proj_dim, random_state)) & 0x7fffffff)\n",
    "        rng = np.random.RandomState(seed)\n",
    "        W = rng.normal(0.0, 1.0 / np.sqrt(D_in), size=(D_in, k))\n",
    "        return X @ W  # (N, k)\n",
    "\n",
    "    # если нужно выровнять размерности — проецируем\n",
    "    if Da != Dm:\n",
    "        A = proj(Xa, Da, \"A\")\n",
    "        M = proj(Xm, Dm, \"M\")\n",
    "    else:\n",
    "        # даже при равных можно оставить как есть, либо тоже проецировать;\n",
    "        # оставим как есть для \"sum/absdiff/hadamard/poly2\", для \"biaffine\" всё равно спроецируем\n",
    "        A, M = Xa, Xm\n",
    "\n",
    "    if fusion == \"sum\":\n",
    "        if A.shape[1] != M.shape[1]:\n",
    "            # на всякий случай приведём к общему k\n",
    "            A = proj(Xa, Da, \"A_sum\")\n",
    "            M = proj(Xm, Dm, \"M_sum\")\n",
    "        return A + M\n",
    "\n",
    "    if fusion == \"hadamard\":\n",
    "        if A.shape[1] != M.shape[1]:\n",
    "            A = proj(Xa, Da, \"A_h\")\n",
    "            M = proj(Xm, Dm, \"M_h\")\n",
    "        return A * M\n",
    "\n",
    "    if fusion == \"absdiff\":\n",
    "        if A.shape[1] != M.shape[1]:\n",
    "            A = proj(Xa, Da, \"A_d\")\n",
    "            M = proj(Xm, Dm, \"M_d\")\n",
    "        return np.abs(A - M)\n",
    "\n",
    "    if fusion == \"biaffine\":\n",
    "        # низкоранговый билинейный: (Xa@U) ⊙ (Xm@V)\n",
    "        k = proj_dim if proj_dim is not None else min(Da, Dm, 256)\n",
    "        seedU = (hash((\"U\", Da, k, random_state)) & 0x7fffffff)\n",
    "        seedV = (hash((\"V\", Dm, k, random_state)) & 0x7fffffff)\n",
    "        rngU = np.random.RandomState(seedU)\n",
    "        rngV = np.random.RandomState(seedV)\n",
    "        U = rngU.normal(0.0, 1.0 / np.sqrt(Da), size=(Da, k))\n",
    "        V = rngV.normal(0.0, 1.0 / np.sqrt(Dm), size=(Dm, k))\n",
    "        Au = Xa @ U\n",
    "        Mv = Xm @ V\n",
    "        return Au * Mv  # (N, k)\n",
    "\n",
    "    if fusion == \"poly2\":\n",
    "        # компактные квадратичные взаимодействия без взрыва размерности\n",
    "        if A.shape[1] != M.shape[1]:\n",
    "            A = proj(Xa, Da, \"A_p2\")\n",
    "            M = proj(Xm, Dm, \"M_p2\")\n",
    "        inter = A * M\n",
    "        diff  = np.abs(A - M)\n",
    "        summ  = A + M\n",
    "        return np.concatenate([A, M, inter, diff, summ], axis=1)\n",
    "\n",
    "    raise ValueError(f\"Unknown fusion mode: {fusion}\")\n",
    "\n",
    "# ---- МАЛЕНЬКАЯ правка твоей функции: одна строка заменена на fuse_features(...) ----\n",
    "def screen_models(\n",
    "    df,\n",
    "    apt_cfgs,\n",
    "    mol_cfgs,\n",
    "    model_names=(\"logreg\",\"rf\",\"lgbm\",\"mlp\"),\n",
    "    split_mode=\"group\",\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    scale=True,\n",
    "    fusion=\"concat\",        # <--- НОВОЕ: способ смешения\n",
    "    proj_dim=256,           # <--- НОВОЕ: размерность проекции для fusion-режимов\n",
    "):\n",
    "    \"\"\"\n",
    "    Возвращает dict {model_name: DataFrame}, где строки — apt-конфиги, колонки — mol-конфиги.\n",
    "    Значение — строка \"PR mean±std | ROC mean±std | F1 mean±std | MCC mean±std | nPR mean±std\".\n",
    "    F1 и MCC — по clf.predict(X). Под капотом фичи смешиваются через `fusion`.\n",
    "    \"\"\"\n",
    "    df = df.reset_index(drop=True)\n",
    "    y = df[\"label\"].to_numpy().astype(int)\n",
    "    splits = _get_splits(df, split_mode=split_mode, n_splits=n_splits, random_state=random_state)\n",
    "\n",
    "    # предрасчёт фич на всём df (как и раньше, чтобы размерности совпадали во всех фолдах)\n",
    "    apt_map = {}\n",
    "    for a in apt_cfgs:\n",
    "        an = _cfg_name(a, 'apt')\n",
    "        apt_map[an] = make_apt_features(df, a)\n",
    "\n",
    "    mol_map = {}\n",
    "    for m in mol_cfgs:\n",
    "        mn = _cfg_name(m, 'mol')\n",
    "        mol_map[mn] = make_mol_features(df, m)\n",
    "\n",
    "    rows = [ _cfg_name(a,'apt') for a in apt_cfgs ]\n",
    "    cols = [ _cfg_name(m,'mol') for m in mol_cfgs ]\n",
    "    results = {}\n",
    "\n",
    "    for model_name in model_names:\n",
    "        clf_proto = _model_factory(model_name, random_state=random_state)\n",
    "        if clf_proto is None:\n",
    "            results[model_name] = pd.DataFrame(\"N/A\", index=rows, columns=cols)\n",
    "            continue\n",
    "\n",
    "        table = pd.DataFrame(index=rows, columns=cols, dtype=object)\n",
    "\n",
    "        for ar in rows:\n",
    "            Xa_full = apt_map[ar].astype(np.float64)\n",
    "            for mc in cols:\n",
    "                Xm_full = mol_map[mc].astype(np.float64)\n",
    "\n",
    "                # НОВОЕ: строим СМЕШАННЫЕ признаки один раз на весь df\n",
    "                X_full = fuse_features(Xa_full, Xm_full, fusion=fusion, proj_dim=proj_dim, random_state=random_state)\n",
    "\n",
    "                pr_list, roc_list, f1_list, mcc_list, npr_list = [], [], [], [], []\n",
    "                for tr, va in splits:\n",
    "                    Xtr, Xva = X_full[tr], X_full[va]\n",
    "                    ytr, yva = y[tr], y[va]\n",
    "\n",
    "                    if scale:\n",
    "                        scaler = StandardScaler()\n",
    "                        Xtr = scaler.fit_transform(Xtr)\n",
    "                        Xva = scaler.transform(Xva)\n",
    "\n",
    "                    clf = _model_factory(model_name, random_state=random_state)\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names.*\")\n",
    "                        clf.fit(Xtr, ytr)\n",
    "\n",
    "                    # непрерывный счёт для PR/ROC\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names.*\")\n",
    "                        if hasattr(clf, \"predict_proba\"):\n",
    "                            s = clf.predict_proba(Xva)[:, 1]\n",
    "                        elif hasattr(clf, \"decision_function\"):\n",
    "                            d = clf.decision_function(Xva)\n",
    "                            s = (d - d.min()) / (d.max() - d.min() + 1e-8)\n",
    "                        else:\n",
    "                            s = clf.predict(Xva).astype(float)\n",
    "\n",
    "                    # бинарные предсказания по дефолтному порогу\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names.*\")\n",
    "                        yhat = clf.predict(Xva)\n",
    "\n",
    "                    pr  = average_precision_score(yva, s) if len(np.unique(yva))>1 else np.nan\n",
    "                    p   = yva.mean()\n",
    "                    npr = (pr - p) / (1 - p + 1e-12)\n",
    "                    roc = roc_auc_score(yva, s) if len(np.unique(yva))>1 else np.nan\n",
    "                    f1  = f1_score(yva, yhat, zero_division=0)\n",
    "                    mcc = matthews_corrcoef(yva, yhat)\n",
    "\n",
    "                    pr_list.append(pr); roc_list.append(roc); f1_list.append(f1); mcc_list.append(mcc); npr_list.append(npr)\n",
    "\n",
    "                def fmt(arr):\n",
    "                    arr = np.array(arr, dtype=float)\n",
    "                    return f\"{np.nanmean(arr):.3f}±{np.nanstd(arr):.3f}\"\n",
    "\n",
    "                table.loc[ar, mc] = (\n",
    "                    f\"PR {fmt(pr_list)} | ROC {fmt(roc_list)} | F1 {fmt(f1_list)} | MCC {fmt(mcc_list)} | nPR {fmt(npr_list)}\"\n",
    "                )\n",
    "\n",
    "        results[model_name] = table\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8814d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug = augment_negatives_per_sequence(df, n_neg_per_seq=3, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "145d88ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# аптамер: только kmer(k=3)\n",
    "apt_cfgs = [\n",
    "    {\"name\": \"kmer\", \"k\": 4},\n",
    "]\n",
    "\n",
    "# молекула: только ChemBERTa (использует уже загруженные tok, mdl)\n",
    "mol_cfgs = [\n",
    "    {\"name\": \"chemberta\", \"tok\": tok, \"mdl\": mdl, \"batch_size\": 64, \"max_len\": 128, \"pooling\": \"mean\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1c21a407",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# примеры:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m res_concat   \u001b[38;5;241m=\u001b[39m screen_models(df_aug, apt_cfgs, mol_cfgs, model_names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlgbm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      3\u001b[0m                             split_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcold_molecule\u001b[39m\u001b[38;5;124m\"\u001b[39m, fusion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m res_hadamard \u001b[38;5;241m=\u001b[39m \u001b[43mscreen_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapt_cfgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmol_cfgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlgbm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msplit_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcold_molecule\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfusion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhadamard\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproj_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m res_poly2    \u001b[38;5;241m=\u001b[39m screen_models(df_aug, apt_cfgs, mol_cfgs, model_names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlgbm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      9\u001b[0m                             split_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcold_molecule\u001b[39m\u001b[38;5;124m\"\u001b[39m, fusion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoly2\u001b[39m\u001b[38;5;124m\"\u001b[39m, proj_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m     11\u001b[0m res_biaffine \u001b[38;5;241m=\u001b[39m screen_models(df_aug, apt_cfgs, mol_cfgs, model_names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlgbm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     12\u001b[0m                             split_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcold_molecule\u001b[39m\u001b[38;5;124m\"\u001b[39m, fusion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiaffine\u001b[39m\u001b[38;5;124m\"\u001b[39m, proj_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n",
      "Cell \u001b[1;32mIn[52], line 122\u001b[0m, in \u001b[0;36mscreen_models\u001b[1;34m(df, apt_cfgs, mol_cfgs, model_names, split_mode, n_splits, random_state, scale, fusion, proj_dim)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m mol_cfgs:\n\u001b[0;32m    121\u001b[0m     mn \u001b[38;5;241m=\u001b[39m _cfg_name(m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmol\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 122\u001b[0m     mol_map[mn] \u001b[38;5;241m=\u001b[39m \u001b[43mmake_mol_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m rows \u001b[38;5;241m=\u001b[39m [ _cfg_name(a,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapt\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m apt_cfgs ]\n\u001b[0;32m    125\u001b[0m cols \u001b[38;5;241m=\u001b[39m [ _cfg_name(m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmol\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m mol_cfgs ]\n",
      "Cell \u001b[1;32mIn[23], line 67\u001b[0m, in \u001b[0;36mmake_mol_features\u001b[1;34m(df, cfg)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchemberta\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     66\u001b[0m     tok \u001b[38;5;241m=\u001b[39m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtok\u001b[39m\u001b[38;5;124m'\u001b[39m]; mdl \u001b[38;5;241m=\u001b[39m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmdl\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchemberta_embed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43msmiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmdl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_len\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpooling\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcat\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     76\u001b[0m     mats \u001b[38;5;241m=\u001b[39m [make_mol_features(df, c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m'\u001b[39m, [])]\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 12\u001b[0m, in \u001b[0;36mchemberta_embed\u001b[1;34m(smiles_list, tok, mdl, batch_size, max_len, pooling, device)\u001b[0m\n\u001b[0;32m     10\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m smiles_list[i:i\u001b[38;5;241m+\u001b[39mbatch_size]]\n\u001b[0;32m     11\u001b[0m enc \u001b[38;5;241m=\u001b[39m tok(batch, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39mmax_len, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 12\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mmdl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43menc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state \n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pooling \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     14\u001b[0m     pooled \u001b[38;5;241m=\u001b[39m h[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:868\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    866\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 868\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    882\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:609\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    605\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[0;32m    607\u001b[0m layer_head_mask \u001b[38;5;241m=\u001b[39m head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 609\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_layers.py:93\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:547\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, cache_position)\u001b[0m\n\u001b[0;32m    544\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    545\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add cross attentions if we output attention weights\u001b[39;00m\n\u001b[1;32m--> 547\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    550\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pytorch_utils.py:251\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:555\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m--> 555\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    556\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:471\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    470\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m--> 471\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_act_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\m19er\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\activations.py:69\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # примеры:\n",
    "res_concat   = screen_models(df_aug, apt_cfgs, mol_cfgs, model_names=(\"lgbm\",\"mlp\"),\n",
    "                             split_mode=\"cold_molecule\", fusion=\"concat\")\n",
    "\n",
    "res_hadamard = screen_models(df_aug, apt_cfgs, mol_cfgs, model_names=(\"lgbm\",\"mlp\"),\n",
    "                             split_mode=\"cold_molecule\", fusion=\"hadamard\", proj_dim=256)\n",
    "\n",
    "res_poly2    = screen_models(df_aug, apt_cfgs, mol_cfgs, model_names=(\"lgbm\",\"mlp\"),\n",
    "                             split_mode=\"cold_molecule\", fusion=\"poly2\", proj_dim=256)\n",
    "\n",
    "res_biaffine = screen_models(df_aug, apt_cfgs, mol_cfgs, model_names=(\"lgbm\",\"mlp\"),\n",
    "                             split_mode=\"cold_molecule\", fusion=\"biaffine\", proj_dim=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29ba42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "44e8f98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lgbm':                                              chemberta(mean)\n",
       " kmer(k=4)  PR 0.853±0.015 | ROC 0.897±0.010 | F1 0.768±0....,\n",
       " 'mlp':                                              chemberta(mean)\n",
       " kmer(k=4)  PR 0.796±0.027 | ROC 0.874±0.015 | F1 0.715±0....}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in res_biaffine.keys():\n",
    "    res_biaffine[model].to_excel(f'res_{model}_biaffine_cold_molecule.xlsx')\n",
    "    res_poly2[model].to_excel(f'res_{model}_poly2_cold_molecule.xlsx')\n",
    "    res_concat[model].to_excel(f'res_{model}_concat_cold_molecule.xlsx')\n",
    "    res_hadamard[model].to_excel(f'res_{model}_hadamard_cold_molecule.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c4653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f98113d8",
   "metadata": {},
   "source": [
    "## Final ML classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cb9c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "#  K-mer(4) + ChemBERTa(mean): LGBM/MLP + Optuna\n",
    "#  feature selection, HPO, importance, fold-wise test stats\n",
    "# ============================================\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, roc_auc_score, f1_score, matthews_corrcoef, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ---- ваши функции: используем как есть ----\n",
    "# make_apt_features(df, cfg)\n",
    "# make_mol_features(df, cfg)\n",
    "# _get_splits(df, split_mode=\"group\", n_splits=5, random_state=42)\n",
    "\n",
    "# ---- Optuna ----\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "\n",
    "# --------- утилиты метрик/агрегации ----------\n",
    "def _compute_fold_metrics(y_true, scores, y_pred):\n",
    "    pr = average_precision_score(y_true, scores) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    p = float(np.mean(y_true))\n",
    "    npr = (pr - p) / (1 - p + 1e-12) if not np.isnan(pr) else np.nan\n",
    "    roc = roc_auc_score(y_true, scores) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    return dict(PR=pr, ROC=roc, F1=f1, MCC=mcc, nPR=npr, TN=tn, FP=fp, FN=fn, TP=tp)\n",
    "\n",
    "def _agg_mean_std(arr):\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    return f\"{np.nanmean(arr):.3f}±{np.nanstd(arr):.3f}\"\n",
    "\n",
    "def _print_fold_val_stats(splits, y):\n",
    "    print(\"\\n[Validation (\\\"test\\\") per fold: size and class balance]\")\n",
    "    tot_N = tot_pos = tot_neg = 0\n",
    "    for i, (_, va) in enumerate(splits, 1):\n",
    "        yv = y[va]\n",
    "        pos = int(np.sum(yv == 1)); neg = int(np.sum(yv == 0)); N = len(yv)\n",
    "        tot_N += N; tot_pos += pos; tot_neg += neg\n",
    "        print(f\"  Fold {i}: N={N}, pos={pos}, neg={neg}, pos%={100*pos/max(N,1):.1f}\")\n",
    "    print(f\"  Total (sum over folds): N={tot_N}, pos={tot_pos}, neg={tot_neg}, pos%={100*tot_pos/max(tot_N,1):.1f}\")\n",
    "\n",
    "\n",
    "# --------- построение фич и имён ----------\n",
    "def _build_features_and_names(df, tok, mdl, chem_max_len=128, chem_batch=64):\n",
    "    \"\"\"KMER k=4 + ChemBERTa(mean). Возвращает X, y, names, groups.\"\"\"\n",
    "    apt_cfg = {\"name\": \"kmer\", \"k\": 4}  # фиксировано по ТЗ\n",
    "    mol_cfg = {\"name\": \"chemberta\", \"tok\": tok, \"mdl\": mdl,\n",
    "               \"batch_size\": chem_batch, \"max_len\": chem_max_len, \"pooling\": \"mean\"}\n",
    "\n",
    "    Xa = make_apt_features(df, apt_cfg).astype(np.float32)\n",
    "    Xm = make_mol_features(df, mol_cfg).astype(np.float32)\n",
    "    X = np.concatenate([Xa, Xm], axis=1)\n",
    "    y = df[\"label\"].to_numpy().astype(int)\n",
    "\n",
    "    # имена/группы фич (если нужных генераторов имён нет — синтетически)\n",
    "    na = Xa.shape[1]; nm = Xm.shape[1]\n",
    "    names = [f\"kmer4_f{i}\" for i in range(na)] + [f\"chemberta_f{j}\" for j in range(nm)]\n",
    "    groups = ([\"apt:kmer4\"] * na) + ([\"mol:chemberta\"] * nm)\n",
    "    return X, y, np.array(names, dtype=object), np.array(groups, dtype=object)\n",
    "\n",
    "\n",
    "# --------- быстрый отбор фич через LGBM gain ----------\n",
    "def lgbm_select_topk(X, y, splits, topk_list=(256, 512, 1024), random_state=42):\n",
    "    \"\"\"Черновой LGBM -> gain-важности -> перебор top-k -> лучший по CV MCC.\"\"\"\n",
    "    from lightgbm import LGBMClassifier\n",
    "    # 1) единый LGBM по всему X для грубой важности\n",
    "    base = LGBMClassifier(\n",
    "        n_estimators=600, learning_rate=0.05, num_leaves=64,\n",
    "        subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,\n",
    "        random_state=random_state, n_jobs=-1, verbosity=-1\n",
    "    )\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        base.fit(X, y)\n",
    "\n",
    "    # gain importance (fallback на split при ошибке)\n",
    "    try:\n",
    "        gain = base.booster_.feature_importance(importance_type=\"gain\").astype(float)\n",
    "    except Exception:\n",
    "        gain = base.booster_.feature_importance(importance_type=\"split\").astype(float)\n",
    "\n",
    "    order = np.argsort(gain)[::-1]  # по убыванию\n",
    "    best_k = None; best_mcc = -1e9; best_idx = None\n",
    "\n",
    "    for k in topk_list:\n",
    "        sel = order[:min(k, X.shape[1])]\n",
    "        mcc_scores = []\n",
    "        for tr, va in splits:\n",
    "            Xtr, ytr = X[tr][:, sel], y[tr]\n",
    "            Xva, yva = X[va][:, sel], y[va]\n",
    "            clf = LGBMClassifier(\n",
    "                n_estimators=400, learning_rate=0.05, num_leaves=48,\n",
    "                subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,\n",
    "                random_state=random_state, n_jobs=-1, verbosity=-1\n",
    "            )\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                clf.fit(Xtr, ytr)\n",
    "\n",
    "            # оценки + предсказания\n",
    "            if hasattr(clf, \"predict_proba\"):\n",
    "                s = clf.predict_proba(Xva)[:, 1]\n",
    "            elif hasattr(clf, \"decision_function\"):\n",
    "                d = clf.decision_function(Xva); s = (d - d.min())/(d.max()-d.min()+1e-8)\n",
    "            else:\n",
    "                s = clf.predict(Xva).astype(float)\n",
    "            yhat = clf.predict(Xva)\n",
    "            metr = _compute_fold_metrics(yva, s, yhat)\n",
    "            mcc_scores.append(metr[\"MCC\"])\n",
    "        mcc_mean = float(np.nanmean(mcc_scores))\n",
    "        if mcc_mean > best_mcc:\n",
    "            best_mcc, best_k, best_idx = mcc_mean, k, sel\n",
    "\n",
    "    return best_idx, gain, best_k, best_mcc\n",
    "\n",
    "\n",
    "# --------- LGBM + Optuna ----------\n",
    "def tune_lgbm_optuna(X, y, sel_idx, splits, random_state=42, n_trials=60, timeout=None):\n",
    "    from lightgbm import LGBMClassifier\n",
    "\n",
    "    Xs = X[:, sel_idx].astype(np.float32)\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 1200),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 2e-1, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 256, step=8),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", -1, 16),\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 120),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 100.0, log=True),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 10.0),\n",
    "            \"random_state\": random_state,\n",
    "            \"n_jobs\": -1,\n",
    "            \"verbosity\": -1\n",
    "        }\n",
    "        mcc_scores = []\n",
    "        for fold_id, (tr, va) in enumerate(splits, 1):\n",
    "            Xtr, ytr = Xs[tr], y[tr]\n",
    "            Xva, yva = Xs[va], y[va]\n",
    "            clf = LGBMClassifier(**params)\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                clf.fit(Xtr, ytr)\n",
    "\n",
    "            # continuous & hard predictions\n",
    "            if hasattr(clf, \"predict_proba\"):\n",
    "                s = clf.predict_proba(Xva)[:, 1]\n",
    "            elif hasattr(clf, \"decision_function\"):\n",
    "                d = clf.decision_function(Xva); s = (d - d.min())/(d.max()-d.min()+1e-8)\n",
    "            else:\n",
    "                s = clf.predict(Xva).astype(float)\n",
    "            yhat = clf.predict(Xva)\n",
    "\n",
    "            metr = _compute_fold_metrics(yva, s, yhat)\n",
    "            mcc_scores.append(metr[\"MCC\"])\n",
    "\n",
    "            trial.report(np.nanmean(mcc_scores), step=fold_id)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        return float(np.nanmean(mcc_scores))\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\",\n",
    "                                sampler=TPESampler(seed=random_state),\n",
    "                                pruner=MedianPruner())\n",
    "    study.optimize(objective, n_trials=n_trials, timeout=timeout, show_progress_bar=False)\n",
    "\n",
    "    best_params = study.best_trial.params.copy()\n",
    "\n",
    "    # финальная CV для сводки метрик и важностей\n",
    "    folds_metrics = []\n",
    "    imp_gain = np.zeros(Xs.shape[1], dtype=float)\n",
    "    for (tr, va) in splits:\n",
    "        Xtr, ytr = Xs[tr], y[tr]\n",
    "        Xva, yva = Xs[va], y[va]\n",
    "        clf = LGBMClassifier(**best_params, random_state=random_state, n_jobs=-1, verbosity=-1)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            clf.fit(Xtr, ytr)\n",
    "\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            s = clf.predict_proba(Xva)[:, 1]\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            d = clf.decision_function(Xva); s = (d - d.min())/(d.max()-d.min()+1e-8)\n",
    "        else:\n",
    "            s = clf.predict(Xva).astype(float)\n",
    "        yhat = clf.predict(Xva)\n",
    "\n",
    "        folds_metrics.append(_compute_fold_metrics(yva, s, yhat))\n",
    "\n",
    "        try:\n",
    "            imp_gain += clf.booster_.feature_importance(importance_type=\"gain\")\n",
    "        except Exception:\n",
    "            imp_gain += clf.booster_.feature_importance(importance_type=\"split\")\n",
    "\n",
    "    return best_params, folds_metrics, imp_gain\n",
    "\n",
    "\n",
    "# --------- MLP + Optuna ----------\n",
    "def tune_mlp_optuna(X, y, sel_idx, splits, random_state=42, n_trials=50, timeout=None, max_iter=250):\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "    Xs = X[:, sel_idx].astype(np.float32)\n",
    "\n",
    "    def objective(trial):\n",
    "        n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "        width = trial.suggest_categorical(\"width\", [64, 128, 256, 512])\n",
    "        hidden = tuple([width] * n_layers)\n",
    "\n",
    "        params = {\n",
    "            \"hidden_layer_sizes\": hidden,\n",
    "            \"activation\": trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-6, 1e-2, log=True),\n",
    "            \"learning_rate_init\": trial.suggest_float(\"lr\", 1e-4, 5e-2, log=True),\n",
    "            \"batch_size\": trial.suggest_categorical(\"batch_size\", [64, 128, 256]),\n",
    "            \"solver\": \"adam\",\n",
    "            \"max_iter\": max_iter,\n",
    "            \"early_stopping\": True,\n",
    "            \"n_iter_no_change\": 10,\n",
    "            \"random_state\": random_state\n",
    "        }\n",
    "\n",
    "        mcc_scores = []\n",
    "        for fold_id, (tr, va) in enumerate(splits, 1):\n",
    "            Xtr, ytr = Xs[tr], y[tr]\n",
    "            Xva, yva = Xs[va], y[va]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            Xtr = scaler.fit_transform(Xtr)\n",
    "            Xva = scaler.transform(Xva)\n",
    "\n",
    "            clf = MLPClassifier(**params)\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                clf.fit(Xtr, ytr)\n",
    "\n",
    "            if hasattr(clf, \"predict_proba\"):\n",
    "                s = clf.predict_proba(Xva)[:, 1]\n",
    "            elif hasattr(clf, \"decision_function\"):\n",
    "                d = clf.decision_function(Xva); s = (d - d.min())/(d.max()-d.min()+1e-8)\n",
    "            else:\n",
    "                s = clf.predict(Xva).astype(float)\n",
    "            yhat = clf.predict(Xva)\n",
    "\n",
    "            metr = _compute_fold_metrics(yva, s, yhat)\n",
    "            mcc_scores.append(metr[\"MCC\"])\n",
    "\n",
    "            trial.report(np.nanmean(mcc_scores), step=fold_id)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        return float(np.nanmean(mcc_scores))\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\",\n",
    "                                sampler=TPESampler(seed=random_state),\n",
    "                                pruner=MedianPruner())\n",
    "    study.optimize(objective, n_trials=n_trials, timeout=timeout, show_progress_bar=False)\n",
    "\n",
    "    best_params = study.best_trial.params.copy()\n",
    "\n",
    "    folds_metrics = []\n",
    "    for (tr, va) in splits:\n",
    "        Xtr, ytr = Xs[tr], y[tr]\n",
    "        Xva, yva = Xs[va], y[va]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        Xtr = scaler.fit_transform(Xtr)\n",
    "        Xva = scaler.transform(Xva)\n",
    "\n",
    "        hidden = tuple([best_params[\"width\"]] * best_params[\"n_layers\"])\n",
    "        clf = MLPClassifier(\n",
    "            hidden_layer_sizes=hidden,\n",
    "            activation=best_params[\"activation\"],\n",
    "            alpha=best_params[\"alpha\"],\n",
    "            learning_rate_init=best_params[\"lr\"],\n",
    "            batch_size=best_params[\"batch_size\"],\n",
    "            solver=\"adam\", max_iter=max_iter, early_stopping=True,\n",
    "            n_iter_no_change=10, random_state=random_state\n",
    "        )\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            clf.fit(Xtr, ytr)\n",
    "\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            s = clf.predict_proba(Xva)[:, 1]\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            d = clf.decision_function(Xva); s = (d - d.min())/(d.max()-d.min()+1e-8)\n",
    "        else:\n",
    "            s = clf.predict(Xva).astype(float)\n",
    "        yhat = clf.predict(Xva)\n",
    "\n",
    "        folds_metrics.append(_compute_fold_metrics(yva, s, yhat))\n",
    "\n",
    "    return best_params, folds_metrics\n",
    "\n",
    "\n",
    "# --------- Главная обёртка: полный эксперимент ----------\n",
    "def run_kmer4_chemberta_optuna(\n",
    "    df,\n",
    "    tok, mdl,                 # объекты ChemBERTa (как вы их уже используете)\n",
    "    split_mode=\"group\",\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    # отбор фич\n",
    "    topk_list=(256, 512, 1024, 1536),\n",
    "    # HPO\n",
    "    n_trials_lgbm=100,\n",
    "    n_trials_mlp=100,\n",
    "    timeout_lgbm=None,\n",
    "    timeout_mlp=None,\n",
    "):\n",
    "    df = df.reset_index(drop=True)\n",
    "    # сплиты\n",
    "    splits = _get_splits(df, split_mode=split_mode, n_splits=n_splits, random_state=random_state)\n",
    "\n",
    "    # фичи\n",
    "    X, y, feat_names, groups = _build_features_and_names(df, tok, mdl)\n",
    "    _print_fold_val_stats(splits, y)\n",
    "\n",
    "    # отбор top-k\n",
    "    print(\"\\n[Feature selection] LGBM gain -> top-k sweep\")\n",
    "    sel_idx, gain, best_k, est_mcc = lgbm_select_topk(X, y, splits, topk_list=topk_list, random_state=random_state)\n",
    "    print(f\"  Selected top-k = {len(sel_idx)} (requested best={best_k}), est. CV-MCC={est_mcc:.3f}\")\n",
    "\n",
    "    names_sel  = feat_names[sel_idx]\n",
    "    groups_sel = groups[sel_idx]\n",
    "\n",
    "    # ---- LGBM (Optuna) ----\n",
    "    print(\"\\n[Tuning] LightGBM (Optuna)\")\n",
    "    lgbm_best_params, lgbm_folds, lgbm_imp_gain_sel = tune_lgbm_optuna(\n",
    "        X, y, sel_idx, splits, random_state=random_state,\n",
    "        n_trials=n_trials_lgbm, timeout=timeout_lgbm\n",
    "    )\n",
    "\n",
    "    # групповые важности LGBM\n",
    "    df_imp = pd.DataFrame({\n",
    "        \"feature\": names_sel,\n",
    "        \"group\": groups_sel,\n",
    "        \"gain\": lgbm_imp_gain_sel\n",
    "    })\n",
    "    group_share = (df_imp.groupby(\"group\")[\"gain\"].sum() /\n",
    "                   max(df_imp[\"gain\"].sum(), 1e-12)).sort_values(ascending=False)\n",
    "\n",
    "    top20 = df_imp.sort_values(\"gain\", ascending=False).head(20).reset_index(drop=True)\n",
    "\n",
    "    # метрики LGBM\n",
    "    lgbm_summary = {\n",
    "        \"Model\": \"LGBM\",\n",
    "        \"PR\":  _agg_mean_std([m[\"PR\"] for m in lgbm_folds]),\n",
    "        \"ROC\": _agg_mean_std([m[\"ROC\"] for m in lgbm_folds]),\n",
    "        \"F1\":  _agg_mean_std([m[\"F1\"] for m in lgbm_folds]),\n",
    "        \"MCC\": _agg_mean_std([m[\"MCC\"] for m in lgbm_folds]),\n",
    "        \"nPR\": _agg_mean_std([m[\"nPR\"] for m in lgbm_folds]),\n",
    "    }\n",
    "    TN = int(sum(m[\"TN\"] for m in lgbm_folds)); FP = int(sum(m[\"FP\"] for m in lgbm_folds))\n",
    "    FN = int(sum(m[\"FN\"] for m in lgbm_folds)); TP = int(sum(m[\"TP\"] for m in lgbm_folds))\n",
    "    lgbm_cm = dict(TN=TN, FP=FP, FN=FN, TP=TP)\n",
    "\n",
    "    # ---- MLP (Optuna) ----\n",
    "    print(\"\\n[Tuning] MLP (Optuna)\")\n",
    "    mlp_best_params, mlp_folds = tune_mlp_optuna(\n",
    "        X, y, sel_idx, splits, random_state=random_state,\n",
    "        n_trials=n_trials_mlp, timeout=timeout_mlp\n",
    "    )\n",
    "    mlp_summary = {\n",
    "        \"Model\": \"MLP\",\n",
    "        \"PR\":  _agg_mean_std([m[\"PR\"] for m in mlp_folds]),\n",
    "        \"ROC\": _agg_mean_std([m[\"ROC\"] for m in mlp_folds]),\n",
    "        \"F1\":  _agg_mean_std([m[\"F1\"] for m in mlp_folds]),\n",
    "        \"MCC\": _agg_mean_std([m[\"MCC\"] for m in mlp_folds]),\n",
    "        \"nPR\": _agg_mean_std([m[\"nPR\"] for m in mlp_folds]),\n",
    "    }\n",
    "    TN = int(sum(m[\"TN\"] for m in mlp_folds)); FP = int(sum(m[\"FP\"] for m in mlp_folds))\n",
    "    FN = int(sum(m[\"FN\"] for m in mlp_folds)); TP = int(sum(m[\"TP\"] for m in mlp_folds))\n",
    "    mlp_cm = dict(TN=TN, FP=FP, FN=FN, TP=TP)\n",
    "\n",
    "    # итоговая таблица\n",
    "    metrics_table = pd.DataFrame([lgbm_summary, mlp_summary]).set_index(\"Model\")\n",
    "    print(\"\\n=== CV metrics (kmer4 + ChemBERTa mean) ===\")\n",
    "    print(metrics_table)\n",
    "\n",
    "    print(\"\\n=== LGBM best params (Optuna) ===\")\n",
    "    print(lgbm_best_params)\n",
    "    print(\"\\n=== MLP best params (Optuna) ===\")\n",
    "    print(mlp_best_params)\n",
    "\n",
    "    print(\"\\n=== LGBM group importance (share over selected) ===\")\n",
    "    print(group_share.to_frame(name=\"share\"))\n",
    "    print(\"\\n=== Top-20 LGBM features (gain) ===\")\n",
    "    print(top20)\n",
    "\n",
    "    print(\"\\n=== Confusion matrices (sum over folds) ===\")\n",
    "    print(\"LGBM:\", lgbm_cm)\n",
    "    print(\"MLP :\", mlp_cm)\n",
    "\n",
    "    artifacts = {\n",
    "        \"selected_idx\": sel_idx,\n",
    "        \"selected_feature_names\": names_sel.tolist(),\n",
    "        \"selected_feature_groups\": groups_sel.tolist(),\n",
    "        \"gain_all\": gain,  # сырая важность до отбора\n",
    "        \"metrics_table\": metrics_table,\n",
    "        \"lgbm_best_params\": lgbm_best_params,\n",
    "        \"mlp_best_params\": mlp_best_params,\n",
    "        \"lgbm_group_importance_share\": group_share.to_dict(),\n",
    "        \"lgbm_top20_features\": top20,\n",
    "        \"lgbm_confusion\": lgbm_cm,\n",
    "        \"mlp_confusion\": mlp_cm,\n",
    "        \"splits\": splits,  # на случай дальнейшего анализа\n",
    "    }\n",
    "    return artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db4c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# допустим, у вас уже есть df (в т.ч. df_aug), а также объекты токенайзера/модели ChemBERTa: tok, mdl\n",
    "\n",
    "art = run_kmer4_chemberta_optuna(\n",
    "    df_aug, tok, mdl,\n",
    "    split_mode=\"group\",      # или \"cold_aptamer\" / \"cold_molecule\" / \"cold_both\"\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    topk_list=(256, 512, 1024, 1536),\n",
    "    n_trials_lgbm=100,\n",
    "    n_trials_mlp=100,\n",
    "    timeout_lgbm=None,\n",
    "    timeout_mlp=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeab323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "#  Evaluate best LGBM (from artifacts) on cold_* splits\n",
    "#  (kmer4 + ChemBERTa mean, same selected_idx & best params)\n",
    "# =========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, f1_score, matthews_corrcoef, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler  # не обяз. для LGBM, но не мешает\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# ---- вспомогательные функции (как в прошлой ячейке) ----\n",
    "def _compute_fold_metrics(y_true, scores, y_pred):\n",
    "    pr = average_precision_score(y_true, scores) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    p = float(np.mean(y_true))\n",
    "    npr = (pr - p) / (1 - p + 1e-12) if not np.isnan(pr) else np.nan\n",
    "    roc = roc_auc_score(y_true, scores) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    return dict(PR=pr, ROC=roc, F1=f1, MCC=mcc, nPR=npr, TN=tn, FP=fp, FN=fn, TP=tp)\n",
    "\n",
    "def _agg_mean_std(arr):\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    return f\"{np.nanmean(arr):.3f}±{np.nanstd(arr):.3f}\"\n",
    "\n",
    "def _print_fold_val_stats(splits, y, title=\"Validation per fold\"):\n",
    "    print(f\"\\n[{title}: size and class balance]\")\n",
    "    tot_N = tot_pos = tot_neg = 0\n",
    "    for i, (_, va) in enumerate(splits, 1):\n",
    "        yv = y[va]\n",
    "        pos = int(np.sum(yv == 1)); neg = int(np.sum(yv == 0)); N = len(yv)\n",
    "        tot_N += N; tot_pos += pos; tot_neg += neg\n",
    "        print(f\"  Fold {i}: N={N}, pos={pos}, neg={neg}, pos%={100*pos/max(N,1):.1f}\")\n",
    "    print(f\"  Total: N={tot_N}, pos={tot_pos}, neg={tot_neg}, pos%={100*tot_pos/max(tot_N,1):.1f}\")\n",
    "\n",
    "# ---- фичи kmer(4)+ChemBERTa(mean) (как раньше) ----\n",
    "def _build_features_kmer4_chemberta(df, tok, mdl, chem_max_len=128, chem_batch=64):\n",
    "    apt_cfg = {\"name\": \"kmer\", \"k\": 4}\n",
    "    mol_cfg = {\"name\": \"chemberta\", \"tok\": tok, \"mdl\": mdl,\n",
    "               \"batch_size\": chem_batch, \"max_len\": chem_max_len, \"pooling\": \"mean\"}\n",
    "    Xa = make_apt_features(df, apt_cfg).astype(np.float32)\n",
    "    Xm = make_mol_features(df, mol_cfg).astype(np.float32)\n",
    "    X = np.concatenate([Xa, Xm], axis=1)\n",
    "    y = df[\"label\"].to_numpy().astype(int)\n",
    "    return X, y\n",
    "\n",
    "def _parse_mean_from_cell(cell):\n",
    "    \"\"\"Парсим '0.706±0.015' -> 0.706 (float).\"\"\"\n",
    "    try:\n",
    "        return float(str(cell).split(\"±\")[0].strip())\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def evaluate_lgbm_on_split(df, tok, mdl, artifacts, split_mode, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Оцениваем лучшую LGBM (из artifacts) на заданном split_mode ('cold_aptamer'/'cold_molecule').\n",
    "    Используем те же selected_idx и best_params, что и для group-бейзлайна.\n",
    "    \"\"\"\n",
    "    # фичи\n",
    "    X, y = _build_features_kmer4_chemberta(df, tok, mdl)\n",
    "    # сплиты\n",
    "    splits = _get_splits(df, split_mode=split_mode, n_splits=n_splits, random_state=random_state)\n",
    "    _print_fold_val_stats(splits, y, title=f'{split_mode} validation')\n",
    "\n",
    "    # выбранные фичи и лучшие параметры\n",
    "    sel_idx = artifacts.get(\"selected_idx\", None)\n",
    "    if sel_idx is not None:\n",
    "        Xs = X[:, sel_idx].astype(np.float32)\n",
    "    else:\n",
    "        Xs = X.astype(np.float32)  # fallback, если по какой-то причине нет отбора\n",
    "    best_params = dict(artifacts[\"lgbm_best_params\"])  # копия\n",
    "    best_params.update(dict(random_state=random_state, n_jobs=-1, verbosity=-1))\n",
    "\n",
    "    folds_metrics = []\n",
    "    for tr, va in splits:\n",
    "        Xtr, ytr = Xs[tr], y[tr]\n",
    "        Xva, yva = Xs[va], y[va]\n",
    "\n",
    "        clf = LGBMClassifier(**best_params)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            clf.fit(Xtr, ytr)\n",
    "\n",
    "        # continuous & hard predictions\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            s = clf.predict_proba(Xva)[:, 1]\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            d = clf.decision_function(Xva); s = (d - d.min())/(d.max()-d.min()+1e-8)\n",
    "        else:\n",
    "            s = clf.predict(Xva).astype(float)\n",
    "        yhat = clf.predict(Xva)\n",
    "\n",
    "        folds_metrics.append(_compute_fold_metrics(yva, s, yhat))\n",
    "\n",
    "    # агрегация\n",
    "    summary = {\n",
    "        \"PR\":  _agg_mean_std([m[\"PR\"] for m in folds_metrics]),\n",
    "        \"ROC\": _agg_mean_std([m[\"ROC\"] for m in folds_metrics]),\n",
    "        \"F1\":  _agg_mean_std([m[\"F1\"] for m in folds_metrics]),\n",
    "        \"MCC\": _agg_mean_std([m[\"MCC\"] for m in folds_metrics]),\n",
    "        \"nPR\": _agg_mean_std([m[\"nPR\"] for m in folds_metrics]),\n",
    "    }\n",
    "    cm = dict(\n",
    "        TN=int(sum(m[\"TN\"] for m in folds_metrics)),\n",
    "        FP=int(sum(m[\"FP\"] for m in folds_metrics)),\n",
    "        FN=int(sum(m[\"FN\"] for m in folds_metrics)),\n",
    "        TP=int(sum(m[\"TP\"] for m in folds_metrics)),\n",
    "    )\n",
    "    return summary, cm, folds_metrics\n",
    "\n",
    "def evaluate_best_lgbm_on_cold(df, tok, mdl, artifacts, n_splits=5, random_state=42):\n",
    "    \"\"\"Запуск на cold_aptamer и cold_molecule + сравнительная сводка с baseline (group).\"\"\"\n",
    "    # baseline из artifacts (group)\n",
    "    base_row = artifacts[\"metrics_table\"].loc[\"LGBM\"]\n",
    "    base = {k: _parse_mean_from_cell(base_row[k]) for k in [\"PR\",\"ROC\",\"F1\",\"MCC\",\"nPR\"]}\n",
    "\n",
    "    out = {}\n",
    "    for split_mode in [\"cold_aptamer\", \"cold_molecule\"]:\n",
    "        print(f\"\\n===== LGBM on {split_mode} =====\")\n",
    "        summary, cm, _ = evaluate_lgbm_on_split(\n",
    "            df, tok, mdl, artifacts,\n",
    "            split_mode=split_mode, n_splits=n_splits, random_state=random_state\n",
    "        )\n",
    "        print(\"\\nSummary metrics:\", summary)\n",
    "        print(\"Confusion matrix (sum over folds):\", cm)\n",
    "        # сравнение с baseline (только mean-часть метрик)\n",
    "        comp = {k: float(summary[k].split(\"±\")[0]) - base[k] for k in base.keys()}\n",
    "        print(\"Δ vs. group (mean):\", comp)\n",
    "        out[split_mode] = dict(summary=summary, cm=cm, delta_vs_group=comp)\n",
    "\n",
    "    # компактная табличка сравнения\n",
    "    rows = []\n",
    "    for sm in [\"group\", \"cold_aptamer\", \"cold_molecule\"]:\n",
    "        if sm == \"group\":\n",
    "            rows.append([\"group\"] + [base[k] for k in [\"PR\",\"ROC\",\"F1\",\"MCC\",\"nPR\"]])\n",
    "        else:\n",
    "            s = out[sm][\"summary\"]\n",
    "            rows.append([sm] + [float(s[k].split(\"±\")[0]) for k in [\"PR\",\"ROC\",\"F1\",\"MCC\",\"nPR\"]])\n",
    "    comp_df = pd.DataFrame(rows, columns=[\"split\",\"PR\",\"ROC\",\"F1\",\"MCC\",\"nPR\"]).set_index(\"split\")\n",
    "    print(\"\\n=== Comparison (mean only) ===\")\n",
    "    print(comp_df)\n",
    "\n",
    "    return out, comp_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9410d01",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_aug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m out, comp_df \u001b[38;5;241m=\u001b[39m evaluate_best_lgbm_on_cold(\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mdf_aug\u001b[49m, tok, mdl, artifacts\u001b[38;5;241m=\u001b[39mart,\n\u001b[0;32m      3\u001b[0m     n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_aug' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "out, comp_df = evaluate_best_lgbm_on_cold(\n",
    "    df_aug, tok, mdl, artifacts=art,\n",
    "    n_splits=5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d9e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
